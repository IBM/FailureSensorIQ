{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7047238-80db-417e-a2de-c49ea4de78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5ae925e-ba3b-4a5f-92ed-a5d15b4772b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llm_feature_selector import LLMFeatureSelector\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c4811b7-a5da-449e-9031-1a2db4fbcfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "current = pd.read_csv('CurrentVoltage.csv', index_col='DeviceTimeStamp')\n",
    "overview = pd.read_csv('Overview.csv', index_col='DeviceTimeStamp')\n",
    "power = pd.read_csv('Power.csv', index_col='DeviceTimeStamp')\n",
    "power_factor = pd.read_csv('PowerFactor.csv', index_col='DeviceTimeStamp')\n",
    "total_power = pd.read_csv('TotalPower.csv', index_col='DeviceTimeStamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f252f228-a1cb-4254-9959-34d80d63d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "current.index = pd.to_datetime(current.index)\n",
    "overview.index = pd.to_datetime(overview.index)\n",
    "power.index = pd.to_datetime(power.index)\n",
    "power_factor.index = pd.to_datetime(power_factor.index)\n",
    "total_power.index = pd.to_datetime(total_power.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "714b7fa8-c4c4-448d-a695-8ee8603fa3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = current\n",
    "for df in [overview, power, power_factor, total_power]:\n",
    "    transformer = pd.merge(transformer, df, on='DeviceTimeStamp')\n",
    "transformer = transformer.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e64d4dbd-5288-4c88-b7a5-c92077386229",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer['MOG_A'] = transformer['MOG_A'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ec2acf-e9bd-4b2f-9feb-52bde47ffda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DeviceTimeStamp', 'VL1', 'VL2', 'VL3', 'IL1', 'IL2', 'IL3', 'VL12',\n",
       "       'VL23', 'VL31', 'INUT', 'OTI', 'WTI', 'ATI', 'OLI', 'OTI_A', 'OTI_T',\n",
       "       'MOG_A', 'WL1', 'WL2', 'WL3', 'VAL1', 'VAL2', 'VAL3', 'RVAL1', 'RVAL2',\n",
       "       'RVAL3', 'PFL1', 'PFL2', 'PFL3', 'Avg_PF', 'Sum_PF', 'FRQ', 'THDVL1',\n",
       "       'THDVL2', 'THDVL3', 'THDIL1', 'THDIL2', 'THDIL3', 'MDIL1', 'MDIL2',\n",
       "       'MDIL3', 'KWH', 'KWH_I', 'KVARH', 'KW', 'KVA', 'KVAR', 'MPD', 'MKVAD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6506f4-ddd8-40e5-ae5f-7f6e1a3d6314",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# feature_descriptions = {\n",
    "#     'VL1': 'Phase Line 1',\n",
    "#     'VL2': 'Phase Line 2',\n",
    "#     'VL3': 'Phase Line 3',\n",
    "#     'IL1': 'Current Line 1',\n",
    "#     'IL2': 'Current Line 2',\n",
    "#     'IL3': 'Current Line 3',\n",
    "#     'VL12': 'Voltage line 1 2',\n",
    "#     'VL23': 'Voltage line 2 3',\n",
    "#     'VL31': 'Voltage line 3 1',\n",
    "#     'INUT': 'Neutral Current',\n",
    "#     'OTI': 'Oil Temperature Indicator',\n",
    "#     'WTI': 'Winding Temperature Indicator',\n",
    "#     'ATI': 'Ambient Temperature Indicator',\n",
    "#     'OLI': 'Oil Level Indicator',\n",
    "#     'OTI_A': 'Oil Temperature Indicator Alarm',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c9d5b59-88ad-4f81-87eb-64bb876ca5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'microsoft/phi-4'\n",
    "model_name = 'meta-llama/Llama-3.3-70B-Instruct'\n",
    "prompt_template = 'Select the variables from the list that are most relevant for predicting <target_variable>. ' +\\\n",
    "                  'Provide the variables sorted starting with the one with the highest priority. ' +\\\n",
    "                  'All variables: <all_variables>\\n' + \\\n",
    "                  '```json\\n{\"reasoning\": \"<your reasoning>\", \"selected_variables\": [\"variable 1\", \"variable 2\", ..., \"variable n\"]}\\n```'\n",
    "all_cols = transformer.drop(['DeviceTimeStamp', 'MOG_A'], axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6670e2ca-d764-4d36-8a47-5b0771856e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the variables from the list that are most relevant for predicting magnetic oil gauge fault in electrical transformers. Provide the variables sorted starting with the one with the highest priority. All variables: VL1, VL2, VL3, IL1, IL2, IL3, VL12, VL23, VL31, INUT, OTI, WTI, ATI, OLI, OTI_A, OTI_T, WL1, WL2, WL3, VAL1, VAL2, VAL3, RVAL1, RVAL2, RVAL3, PFL1, PFL2, PFL3, Avg_PF, Sum_PF, FRQ, THDVL1, THDVL2, THDVL3, THDIL1, THDIL2, THDIL3, MDIL1, MDIL2, MDIL3, KWH, KWH_I, KVARH, KW, KVA, KVAR, MPD, MKVAD\n",
      "```json\n",
      "{\"reasoning\": \"<your reasoning>\", \"selected_variables\": [\"variable 1\", \"variable 2\", ..., \"variable n\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.replace('<all_variables>', ', '.join(all_cols))\n",
    "prompt = prompt.replace('<target_variable>', 'magnetic oil gauge fault in electrical transformers')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a42d829b-a545-4160-9080-2ad9c1f30591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3d59c5e294488badf075e1e6844b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d13d773ba5c4d22a3f6c6c70addab76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f45cd61d651401586139c30356589b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d201fd88a24192890d5c1927d91b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe806932c6e040b49e9d183388492620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"selected_variables\": [\"OTI\", \"OLI\", \"INUT\", \"KWH\", \"KW\", \"KVA\", \"KVAR\", \"MDIL1\", \"MDIL2\", \"MDIL3\", \"THDIL1\", \"THDIL2\", \"THDIL3\", \"THDVL1\", \"THDVL2\", \"THDVL3\", \"VL1\", \"VL2\", \"VL3\", \"IL1\", \"IL2\", \"IL3\"]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 48)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_sel = LLMFeatureSelector(model_name=model_name,\n",
    "                              feature_names=all_cols,\n",
    "                              target_variable='magnetic oil gauge fault',\n",
    "                              prompt_template=prompt_template,\n",
    "                              topk=3\n",
    "                             )\n",
    "output = feat_sel.fit(transformer[all_cols])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fcf4542-50d6-406e-a470-f435e38a7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_corrs = transformer.drop('DeviceTimeStamp', axis=1).corr()['MOG_A'].abs().sort_values(ascending=False).to_frame()\n",
    "sorted_corrs['idx'] = np.arange(len(sorted_corrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0993beb-51c7-4382-ae8c-d3816bb254b5",
   "metadata": {},
   "source": [
    "## We manually took the prompt and fed it to ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19d83227-0298-47af-87ad-8f2b65f3355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_response = {\n",
    "  \"reasoning\": \"Magnetic oil gauge faults in electrical transformers are most often linked to issues in oil temperature, pressure, or flow, which in turn are influenced by thermal and electrical stress on the transformer. Variables directly indicating oil and winding temperatures (OTI, WTI, OLI) are critical, as they reflect the thermal state of the transformer and can signal overheating or abnormal cooling—both major contributors to oil-related faults. Load currents (IL1, IL2, IL3) are also important, as high current increases heat generation. Power measurements (KW, KVA), power factor (PFL1-3, Avg_PF), and harmonics (THDIL1-3) can indicate operational stress and efficiency, which affect oil performance. Derived temperature indicators (OTI_A, OTI_T) may provide additional granularity. Voltage metrics and frequency are less directly linked to oil faults unless they're highly unstable, and derived values such as MPD or MKVAD are likely less informative unless defined otherwise. Thus, the selection prioritizes direct indicators of thermal and electrical stress.\",\n",
    "  \"selected_variables\": [\n",
    "    \"OTI\",\n",
    "    \"WTI\",\n",
    "    \"OLI\",\n",
    "    \"OTI_A\",\n",
    "    \"OTI_T\",\n",
    "    \"IL1\",\n",
    "    \"IL2\",\n",
    "    \"IL3\",\n",
    "    \"KW\",\n",
    "    \"KVA\",\n",
    "    \"PFL1\",\n",
    "    \"PFL2\",\n",
    "    \"PFL3\",\n",
    "    \"Avg_PF\",\n",
    "    \"THDIL1\",\n",
    "    \"THDIL2\",\n",
    "    \"THDIL3\",\n",
    "    \"MDIL1\",\n",
    "    \"MDIL2\",\n",
    "    \"MDIL3\",\n",
    "    \"KWH\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7237f7bc-32c9-47f0-a047-bc700bf2f350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7.84 (38)',\n",
       " '12.52 (33)',\n",
       " '20.33 (24)',\n",
       " '0.25 (47)',\n",
       " '0.31 (46)',\n",
       " '28.09 (15)',\n",
       " '35.13 (3)',\n",
       " '27.24 (17)',\n",
       " '29.34 (14)',\n",
       " '29.43 (13)',\n",
       " '4.72 (40)',\n",
       " '7.66 (39)',\n",
       " '22.26 (23)',\n",
       " '13.91 (31)',\n",
       " '1.01 (44)',\n",
       " '10.86 (36)',\n",
       " '3.99 (41)',\n",
       " '27.01 (19)',\n",
       " '35.56 (2)',\n",
       " '26.09 (21)',\n",
       " '19.47 (28)']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{round(sorted_corrs.loc[sorted_corrs.index==rec].iloc[0].MOG_A * 100, 2)} ({int(sorted_corrs.loc[sorted_corrs.index==rec].iloc[0].idx)})' for rec in chatgpt_response['selected_variables']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b054de9-aded-411e-97b5-7d1f7d19d7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
