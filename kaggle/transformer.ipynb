{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7047238-80db-417e-a2de-c49ea4de78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ae925e-ba3b-4a5f-92ed-a5d15b4772b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llm_feature_selector import LLMFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c4811b7-a5da-449e-9031-1a2db4fbcfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "current = pd.read_csv('transformer/CurrentVoltage.csv', index_col='DeviceTimeStamp')\n",
    "overview = pd.read_csv('transformer/Overview.csv', index_col='DeviceTimeStamp')\n",
    "power = pd.read_csv('transformer/Power.csv', index_col='DeviceTimeStamp')\n",
    "power_factor = pd.read_csv('transformer/PowerFactor.csv', index_col='DeviceTimeStamp')\n",
    "total_power = pd.read_csv('transformer/TotalPower.csv', index_col='DeviceTimeStamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f252f228-a1cb-4254-9959-34d80d63d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "current.index = pd.to_datetime(current.index)\n",
    "overview.index = pd.to_datetime(overview.index)\n",
    "power.index = pd.to_datetime(power.index)\n",
    "power_factor.index = pd.to_datetime(power_factor.index)\n",
    "total_power.index = pd.to_datetime(total_power.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "714b7fa8-c4c4-448d-a695-8ee8603fa3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = current\n",
    "for df in [overview, power, power_factor, total_power]:\n",
    "    transformer = pd.merge(transformer, df, on='DeviceTimeStamp')\n",
    "transformer = transformer.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4cba2f5-e893-487a-9bc4-e9ed5b4b325a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# X = transformer.drop(['DeviceTimeStamp','MOG_A'],axis=1)\n",
    "# y = transformer['MOG_A']\n",
    "# xgb = Xgb.XGBClassifier()\n",
    "# xgb.fit(X_train,y_train)\n",
    "# y_pred_xgb = xgb.predict(X_test)\n",
    "# xgb.score(X_train, y_train)\n",
    "\n",
    "# xgb_train = round(xgb.score(X_train, y_train) * 100, 2)\n",
    "# xgb_accuracy = round(accuracy_score(y_pred_xgb, y_test) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6506f4-ddd8-40e5-ae5f-7f6e1a3d6314",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# feature_descriptions = {\n",
    "#     'VL1': 'Phase Line 1',\n",
    "#     'VL2': 'Phase Line 2',\n",
    "#     'VL3': 'Phase Line 3',\n",
    "#     'IL1': 'Current Line 1',\n",
    "#     'IL2': 'Current Line 2',\n",
    "#     'IL3': 'Current Line 3',\n",
    "#     'VL12': 'Voltage line 1 2',\n",
    "#     'VL23': 'Voltage line 2 3',\n",
    "#     'VL31': 'Voltage line 3 1',\n",
    "#     'INUT': 'Neutral Current',\n",
    "#     'OTI': 'Oil Temperature Indicator',\n",
    "#     'WTI': 'Winding Temperature Indicator',\n",
    "#     'ATI': 'Ambient Temperature Indicator',\n",
    "#     'OLI': 'Oil Level Indicator',\n",
    "#     'OTI_A': 'Oil Temperature Indicator Alarm',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c9d5b59-88ad-4f81-87eb-64bb876ca5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'microsoft/phi-4'\n",
    "model_name = 'meta-llama/Llama-3.3-70B-Instruct'\n",
    "prompt_template = 'Select the variables from the list that are most relevant for predicting <target_variable>. ' +\\\n",
    "                  'Provide the variables sorted starting with the one with the highest priority. ' +\\\n",
    "                  'All variables: <all_variables>\\n' + \\\n",
    "                  '```json\\n{\"reasoning\": \"<your reasoning>\", \"selected_variables\": [\"variable 1\", \"variable 2\", ..., \"variable n\"]}\\n```'\n",
    "all_cols = transformer.drop(['DeviceTimeStamp', 'MOG_A'], axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6670e2ca-d764-4d36-8a47-5b0771856e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the variables from the list that are most relevant for predicting magnetic oil gauge fault in electrical transformers. Provide the variables sorted starting with the one with the highest priority. All variables: VL1, VL2, VL3, IL1, IL2, IL3, VL12, VL23, VL31, INUT, OTI, WTI, ATI, OLI, OTI_A, OTI_T, WL1, WL2, WL3, VAL1, VAL2, VAL3, RVAL1, RVAL2, RVAL3, PFL1, PFL2, PFL3, Avg_PF, Sum_PF, FRQ, THDVL1, THDVL2, THDVL3, THDIL1, THDIL2, THDIL3, MDIL1, MDIL2, MDIL3, KWH, KWH_I, KVARH, KW, KVA, KVAR, MPD, MKVAD\n",
      "```json\n",
      "{\"reasoning\": \"<your reasoning>\", \"selected_variables\": [\"variable 1\", \"variable 2\", ..., \"variable n\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.replace('<all_variables>', ', '.join(all_cols))\n",
    "prompt = prompt.replace('<target_variable>', 'magnetic oil gauge fault in electrical transformers')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a42d829b-a545-4160-9080-2ad9c1f30591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3d59c5e294488badf075e1e6844b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d13d773ba5c4d22a3f6c6c70addab76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f45cd61d651401586139c30356589b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d201fd88a24192890d5c1927d91b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe806932c6e040b49e9d183388492620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"selected_variables\": [\"OTI\", \"OLI\", \"INUT\", \"KWH\", \"KW\", \"KVA\", \"KVAR\", \"MDIL1\", \"MDIL2\", \"MDIL3\", \"THDIL1\", \"THDIL2\", \"THDIL3\", \"THDVL1\", \"THDVL2\", \"THDVL3\", \"VL1\", \"VL2\", \"VL3\", \"IL1\", \"IL2\", \"IL3\"]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 48)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_sel = LLMFeatureSelector(model_name=model_name,\n",
    "                              feature_names=all_cols,\n",
    "                              target_variable='magnetic oil gauge fault',\n",
    "                              prompt_template=prompt_template,\n",
    "                              topk=3\n",
    "                             )\n",
    "output = feat_sel.fit(transformer[all_cols])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fcf4542-50d6-406e-a470-f435e38a7afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29291, 48)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_corrs = transformer.drop('DeviceTimeStamp', axis=1).corr()['MOG_A'].abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df8a19dc-1171-49c4-866f-7e97cf50c4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLI 0.20330742879547067\n",
      "OTI 0.07827422647381119\n",
      "OTI_A 0.0024881496650764417\n",
      "OTI_T 0.0030761538542668364\n",
      "ATI 0.007283277548341243\n",
      "WTI 0.12523335014341658\n"
     ]
    }
   ],
   "source": [
    "for rec in output:\n",
    "    print(rec, sorted_corrs[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b054de9-aded-411e-97b5-7d1f7d19d7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
