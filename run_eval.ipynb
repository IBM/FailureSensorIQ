{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd01bf7-47cb-4c40-9496-c2b62fb83ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1db6ab-ccf4-49b2-956c-4338d09e832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('perteval')\n",
    "sys.path.append('uq_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63c915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils import get_requests, get_results\n",
    "from perteval.perteval_end_to_end import get_perteval_results\n",
    "# from uq_score.uq_end_to_end import run_uq\n",
    "from llm_uncertainty_bench.uq_end_to_end import run_uq_benchmark\n",
    "import datetime\n",
    "import perteval.transition_analysis as tas\n",
    "import time\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978b45b7-8727-411f-9f99-4e36bcc2ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try killing old processes that utilize the gpu\n",
    "try:\n",
    "    subprocess.run([\"nvidia-smi | grep 'python' | awk '{ print $5 }' | xargs -n1 kill -9\"], shell=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4108b98f-2ec7-406a-b334-56ddf21f36c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8b8b91bf5e41c58215f4b290d35622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 29 files:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/modelfactory/.cache/huggingface/hub/datasets--cc4718--requests/snapshots/ed8a000faff905923cadd18a9229d2d1b5036768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756298d74a0246a5aefbff10ba254d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 26 files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/modelfactory/.cache/huggingface/hub/datasets--cc4718--results/snapshots/2b7dae5c279fc817670edd2b2eb2774a97b0e415/demo-leaderboard/gpt2-demo\n",
      "{'ibm-granite/granite-3.1-8b-instruct'}\n",
      "full\n"
     ]
    }
   ],
   "source": [
    "if len(sys.argv) == 1 or sys.argv[1] == '-f':\n",
    "    # -f is to avoid the case that this runs as ipynb\n",
    "    all_request_models = get_requests('cc4718/requests')\n",
    "    all_result_models = get_results('cc4718/results')\n",
    "    models_todo = set(all_request_models) - set(all_result_models)\n",
    "    # dataset can be full/sample\n",
    "    dataset = 'full'\n",
    "else:\n",
    "    # huggingface models\n",
    "    models_todo = [sys.argv[1]]\n",
    "    # dataset full/sample\n",
    "    dataset = sys.argv[2]\n",
    "print(models_todo)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8220d2-3eff-49a1-95dd-0dc02ac31161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Log path: ./log/fmsr_filtered_data_full_2025-06-05T11:28:29.jsonl\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric motor, if a failure event rotor windings fault occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A partial discharge\n",
      "B resistance\n",
      "C oil debris\n",
      "D current\n",
      "E voltage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with bearing damage in electric generator, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A power\n",
      "B voltage\n",
      "C current\n",
      "D oil debris\n",
      "E cooling gas\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When coast down time detects abnormal readings in pump, which failure mode is the most relevant?\n",
      "Options:\n",
      "A misalignment\n",
      "B unbalance\n",
      "C bearing wear\n",
      "D mounting fault\n",
      "E damaged seals\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting damaged rotor blade in steam turbine?\n",
      "Options:\n",
      "A temperature\n",
      "B length measurement\n",
      "C oil debris\n",
      "D coast down time\n",
      "E steam leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When considering misalignment in compressor, which sensor should be disregarded from the choices for monitoring this failure?\n",
      "Options:\n",
      "A speed\n",
      "B length measurement\n",
      "C vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of overheating/ auxiliary cooling system fault in power transformer?\n",
      "Options:\n",
      "A ultrasound\n",
      "B oil condition\n",
      "C resistance\n",
      "D dissolved gas analysis\n",
      "E visual\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For aero gas turbine, which failure event is not pertinent if the sensor vibration registers an abnormal reading?\n",
      "Options:\n",
      "A bearing wear/ damage\n",
      "B misalignment\n",
      "C compressor fouled\n",
      "D compressor stall\n",
      "E fuel filter blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor current in electric generator shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A loss of output power phase\n",
      "B unbalance\n",
      "C brush(es) fault\n",
      "D stator windings fault\n",
      "E eccentric rotor\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples = 2667\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1670, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of overheating/ auxiliary cooling system fault in power transformer?\\nOptions:\\nA ultrasound\\nB oil condition\\nC resistance\\nD dissolved gas analysis\\nE visual\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of overheating/ auxiliary cooling system fault in power transformer?', 'options_text': ['ultrasound', 'oil condition', 'resistance', 'dissolved gas analysis', 'visual'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of overheating/ auxiliary cooling system fault in power transformer?\n",
      "Options:\n",
      "A visual\n",
      "B oil condition\n",
      "C dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "D dissolved gas analysis\n",
      "E ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 334, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with bearing damage in electric generator, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA power\\nB voltage\\nC current\\nD oil debris\\nE cooling gas\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with bearing damage in electric generator, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['power', 'voltage', 'current', 'oil debris', 'cooling gas'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2338, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor current in electric generator shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA loss of output power phase\\nB unbalance\\nC brush(es) fault\\nD stator windings fault\\nE eccentric rotor\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor current in electric generator shows an abnormal reading, which failure event is insignificant?', 'options_text': ['loss of output power phase', 'unbalance', 'brush(es) fault', 'stator windings fault', 'eccentric rotor'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 668, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When coast down time detects abnormal readings in pump, which failure mode is the most relevant?\\nOptions:\\nA misalignment\\nB unbalance\\nC bearing wear\\nD mounting fault\\nE damaged seals\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When coast down time detects abnormal readings in pump, which failure mode is the most relevant?', 'options_text': ['misalignment', 'unbalance', 'bearing wear', 'mounting fault', 'damaged seals'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices provides the strongest indication of insulation deterioration in electric generator?\n",
      "Options:\n",
      "A oil debris\n",
      "B axial flux\n",
      "C vibration\n",
      "D current\n",
      "E coast down\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2004, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For aero gas turbine, which failure event is not pertinent if the sensor vibration registers an abnormal reading?\\nOptions:\\nA bearing wear/ damage\\nB misalignment\\nC compressor fouled\\nD compressor stall\\nE fuel filter blockage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For aero gas turbine, which failure event is not pertinent if the sensor vibration registers an abnormal reading?', 'options_text': ['bearing wear/ damage', 'misalignment', 'compressor fouled', 'compressor stall', 'fuel filter blockage'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor current in electric generator shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B eccentric rotor\n",
      "C misalignment\n",
      "D insulation deterioration\n",
      "E loss of output power phase\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For pump, what is the key failure mode when oil debris has abnormal readings?\n",
      "Options:\n",
      "A unbalance\n",
      "B mounting fault\n",
      "C eccentric impeller\n",
      "D damaged impeller\n",
      "E damaged seals\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In aero gas turbine, which failure event is unimportant if the sensor vibration shows an abnormal reading?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B unbalance\n",
      "C power turbine damage\n",
      "D seal leakage\n",
      "E misalignment\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1671, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of overheating/ auxiliary cooling system fault in power transformer?\\nOptions:\\nA visual\\nB oil condition\\nC dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nD dissolved gas analysis\\nE ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of overheating/ auxiliary cooling system fault in power transformer?', 'options_text': ['visual', 'oil condition', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'dissolved gas analysis', 'ultrasound'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 335, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices provides the strongest indication of insulation deterioration in electric generator?\\nOptions:\\nA oil debris\\nB axial flux\\nC vibration\\nD current\\nE coast down\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices provides the strongest indication of insulation deterioration in electric generator?', 'options_text': ['oil debris', 'axial flux', 'vibration', 'current', 'coast down'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2339, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor current in electric generator shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA brush(es) fault\\nB eccentric rotor\\nC misalignment\\nD insulation deterioration\\nE loss of output power phase\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor current in electric generator shows an abnormal reading, which failure event is insignificant?', 'options_text': ['brush(es) fault', 'eccentric rotor', 'misalignment', 'insulation deterioration', 'loss of output power phase'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 669, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For pump, what is the key failure mode when oil debris has abnormal readings?\\nOptions:\\nA unbalance\\nB mounting fault\\nC eccentric impeller\\nD damaged impeller\\nE damaged seals\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For pump, what is the key failure mode when oil debris has abnormal readings?', 'options_text': ['unbalance', 'mounting fault', 'eccentric impeller', 'damaged impeller', 'damaged seals'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices does not indicate the presence of overheating/ auxiliary cooling system fault in asset power transformer?\n",
      "Options:\n",
      "A dissolved gas analysis\n",
      "B ultrasound\n",
      "C frequency response analysis (fra)\n",
      "D visual\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2005, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In aero gas turbine, which failure event is unimportant if the sensor vibration shows an abnormal reading?\\nOptions:\\nA compressor fouled\\nB unbalance\\nC power turbine damage\\nD seal leakage\\nE misalignment\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In aero gas turbine, which failure event is unimportant if the sensor vibration shows an abnormal reading?', 'options_text': ['compressor fouled', 'unbalance', 'power turbine damage', 'seal leakage', 'misalignment'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, if a failure event insulation deterioration occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A axial flux\n",
      "B temparature\n",
      "C torque\n",
      "D power\n",
      "E voltage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for electric generator if the sensor voltage exhibits an abnormal reading?\n",
      "Options:\n",
      "A rotor windings fault\n",
      "B loss of output power phase\n",
      "C brush(es) fault\n",
      "D insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In pump, which failure mode is most important if oil debris shows abnormal readings?\n",
      "Options:\n",
      "A unbalance\n",
      "B damaged seals\n",
      "C eccentric impeller\n",
      "D bearing damage\n",
      "E mounting fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For aero gas turbine, which failure event is not pertinent if the sensor vibration registers an abnormal reading?\n",
      "Options:\n",
      "A bearing wear/ damage\n",
      "B misalignment\n",
      "C unbalance\n",
      "D compressor stall\n",
      "E combustion chamber holed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2006, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For aero gas turbine, which failure event is not pertinent if the sensor vibration registers an abnormal reading?\\nOptions:\\nA bearing wear/ damage\\nB misalignment\\nC unbalance\\nD compressor stall\\nE combustion chamber holed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For aero gas turbine, which failure event is not pertinent if the sensor vibration registers an abnormal reading?', 'options_text': ['bearing wear/ damage', 'misalignment', 'unbalance', 'compressor stall', 'combustion chamber holed'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 336, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, if a failure event insulation deterioration occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\\nOptions:\\nA axial flux\\nB temparature\\nC torque\\nD power\\nE voltage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, if a failure event insulation deterioration occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?', 'options_text': ['axial flux', 'temparature', 'torque', 'power', 'voltage'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 670, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In pump, which failure mode is most important if oil debris shows abnormal readings?\\nOptions:\\nA unbalance\\nB damaged seals\\nC eccentric impeller\\nD bearing damage\\nE mounting fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In pump, which failure mode is most important if oil debris shows abnormal readings?', 'options_text': ['unbalance', 'damaged seals', 'eccentric impeller', 'bearing damage', 'mounting fault'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for aero gas turbine when an abnormal reading is detected by the sensor vibration?\n",
      "Options:\n",
      "A burner blocked\n",
      "B bearing wear/ damage\n",
      "C power turbine dirty\n",
      "D power turbine damage\n",
      "E compressor stall\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2340, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for electric generator if the sensor voltage exhibits an abnormal reading?\\nOptions:\\nA rotor windings fault\\nB loss of output power phase\\nC brush(es) fault\\nD insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for electric generator if the sensor voltage exhibits an abnormal reading?', 'options_text': ['rotor windings fault', 'loss of output power phase', 'brush(es) fault', 'insulation deterioration'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In electric generator, when insulation deterioration occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\n",
      "Options:\n",
      "A torque\n",
      "B axial flux\n",
      "C resistance\n",
      "D power\n",
      "E radio frequency emissions\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1672, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices does not indicate the presence of overheating/ auxiliary cooling system fault in asset power transformer?\\nOptions:\\nA dissolved gas analysis\\nB ultrasound\\nC frequency response analysis (fra)\\nD visual\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices does not indicate the presence of overheating/ auxiliary cooling system fault in asset power transformer?', 'options_text': ['dissolved gas analysis', 'ultrasound', 'frequency response analysis (fra)', 'visual', 'temperature'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When oil debris in pump displays abnormal readings, which failure mode is the most applicable?\n",
      "Options:\n",
      "A unbalance\n",
      "B mounting fault\n",
      "C misalignment\n",
      "D bearing wear\n",
      "E damaged seals\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of electric generator, which failure event is not relevant when the sensor voltage shows an abnormal reading?\n",
      "Options:\n",
      "A stator windings fault\n",
      "B loss of output power phase\n",
      "C brush(es) fault\n",
      "D insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting overheating/ auxiliary cooling system fault in power transformer?\n",
      "Options:\n",
      "A excitation current\n",
      "B dissolved gas analysis\n",
      "C temperature\n",
      "D ultrasound\n",
      "E visual\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 337, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In electric generator, when insulation deterioration occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\\nOptions:\\nA torque\\nB axial flux\\nC resistance\\nD power\\nE radio frequency emissions\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In electric generator, when insulation deterioration occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?', 'options_text': ['torque', 'axial flux', 'resistance', 'power', 'radio frequency emissions'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 671, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When oil debris in pump displays abnormal readings, which failure mode is the most applicable?\\nOptions:\\nA unbalance\\nB mounting fault\\nC misalignment\\nD bearing wear\\nE damaged seals\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When oil debris in pump displays abnormal readings, which failure mode is the most applicable?', 'options_text': ['unbalance', 'mounting fault', 'misalignment', 'bearing wear', 'damaged seals'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1673, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor from the choices does not contribute significantly to detecting overheating/ auxiliary cooling system fault in power transformer?\\nOptions:\\nA excitation current\\nB dissolved gas analysis\\nC temperature\\nD ultrasound\\nE visual\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor from the choices does not contribute significantly to detecting overheating/ auxiliary cooling system fault in power transformer?', 'options_text': ['excitation current', 'dissolved gas analysis', 'temperature', 'ultrasound', 'visual'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor among the choices best correlates with the presence of insulation deterioration in asset electric generator?\n",
      "Options:\n",
      "A torque\n",
      "B vibration\n",
      "C power\n",
      "D partial discharge\n",
      "E oil debris\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2341, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of electric generator, which failure event is not relevant when the sensor voltage shows an abnormal reading?\\nOptions:\\nA stator windings fault\\nB loss of output power phase\\nC brush(es) fault\\nD insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of electric generator, which failure event is not relevant when the sensor voltage shows an abnormal reading?', 'options_text': ['stator windings fault', 'loss of output power phase', 'brush(es) fault', 'insulation deterioration'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2007, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for aero gas turbine when an abnormal reading is detected by the sensor vibration?\\nOptions:\\nA burner blocked\\nB bearing wear/ damage\\nC power turbine dirty\\nD power turbine damage\\nE compressor stall\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for aero gas turbine when an abnormal reading is detected by the sensor vibration?', 'options_text': ['burner blocked', 'bearing wear/ damage', 'power turbine dirty', 'power turbine damage', 'compressor stall'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For pump, which failure mode is pertinent if oil leakage registers abnormal readings?\n",
      "Options:\n",
      "A misalignment\n",
      "B bearing damage\n",
      "C eccentric impeller\n",
      "D mounting fault\n",
      "E damaged seals\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of overheating/ auxiliary cooling system fault in power transformer?\n",
      "Options:\n",
      "A visual\n",
      "B leak reactance flux\n",
      "C dissolved gas analysis\n",
      "D ultrasound\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor voltage?\n",
      "Options:\n",
      "A eccentric rotor\n",
      "B loss of output power phase\n",
      "C brush(es) fault\n",
      "D insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor oil debris in aero gas turbine shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A compressor damaged\n",
      "B seal leakage\n",
      "C compressor fouled\n",
      "D air inlet blockage\n",
      "E gear defects\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 338, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor among the choices best correlates with the presence of insulation deterioration in asset electric generator?\\nOptions:\\nA torque\\nB vibration\\nC power\\nD partial discharge\\nE oil debris\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor among the choices best correlates with the presence of insulation deterioration in asset electric generator?', 'options_text': ['torque', 'vibration', 'power', 'partial discharge', 'oil debris'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2342, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor voltage?\\nOptions:\\nA eccentric rotor\\nB loss of output power phase\\nC brush(es) fault\\nD insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor voltage?', 'options_text': ['eccentric rotor', 'loss of output power phase', 'brush(es) fault', 'insulation deterioration'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1674, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of overheating/ auxiliary cooling system fault in power transformer?\\nOptions:\\nA visual\\nB leak reactance flux\\nC dissolved gas analysis\\nD ultrasound\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of overheating/ auxiliary cooling system fault in power transformer?', 'options_text': ['visual', 'leak reactance flux', 'dissolved gas analysis', 'ultrasound', 'temperature'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2008, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor oil debris in aero gas turbine shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA compressor damaged\\nB seal leakage\\nC compressor fouled\\nD air inlet blockage\\nE gear defects\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor oil debris in aero gas turbine shows an abnormal reading, which failure event is insignificant?', 'options_text': ['compressor damaged', 'seal leakage', 'compressor fouled', 'air inlet blockage', 'gear defects'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices can indicate the presence of insulation deterioration in asset electric generator?\n",
      "Options:\n",
      "A cooling gas\n",
      "B oil debris\n",
      "C temparature\n",
      "D vibration\n",
      "E power\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 672, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For pump, which failure mode is pertinent if oil leakage registers abnormal readings?\\nOptions:\\nA misalignment\\nB bearing damage\\nC eccentric impeller\\nD mounting fault\\nE damaged seals\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For pump, which failure mode is pertinent if oil leakage registers abnormal readings?', 'options_text': ['misalignment', 'bearing damage', 'eccentric impeller', 'mounting fault', 'damaged seals'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, which failure event is not pertinent if the sensor voltage registers an abnormal reading?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B insulation deterioration\n",
      "C loss of output power phase\n",
      "D bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices does not indicate the presence of overheating/ auxiliary cooling system fault in asset power transformer?\n",
      "Options:\n",
      "A visual\n",
      "B oil condition\n",
      "C temperature\n",
      "D bushing capacitance\n",
      "E dissolved gas analysis\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For aero gas turbine, which failure event is not pertinent if the sensor oil debris registers an abnormal reading?\n",
      "Options:\n",
      "A power turbine damage\n",
      "B compressor stall\n",
      "C bearing wear/ damage\n",
      "D compressor damaged\n",
      "E seal leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When fluid leakage detects abnormal readings in compressor, which failure mode is the most relevant?\n",
      "Options:\n",
      "A bearing wear\n",
      "B misalignment\n",
      "C damaged seals\n",
      "D damaged impeller\n",
      "E eccentric impeller\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1675, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices does not indicate the presence of overheating/ auxiliary cooling system fault in asset power transformer?\\nOptions:\\nA visual\\nB oil condition\\nC temperature\\nD bushing capacitance\\nE dissolved gas analysis\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices does not indicate the presence of overheating/ auxiliary cooling system fault in asset power transformer?', 'options_text': ['visual', 'oil condition', 'temperature', 'bushing capacitance', 'dissolved gas analysis'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2343, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, which failure event is not pertinent if the sensor voltage registers an abnormal reading?\\nOptions:\\nA brush(es) fault\\nB insulation deterioration\\nC loss of output power phase\\nD bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, which failure event is not pertinent if the sensor voltage registers an abnormal reading?', 'options_text': ['brush(es) fault', 'insulation deterioration', 'loss of output power phase', 'bearing damage'], 'true_answer': [False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2009, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For aero gas turbine, which failure event is not pertinent if the sensor oil debris registers an abnormal reading?\\nOptions:\\nA power turbine damage\\nB compressor stall\\nC bearing wear/ damage\\nD compressor damaged\\nE seal leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For aero gas turbine, which failure event is not pertinent if the sensor oil debris registers an abnormal reading?', 'options_text': ['power turbine damage', 'compressor stall', 'bearing wear/ damage', 'compressor damaged', 'seal leakage'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices does not indicate the presence of low oil level in asset power transformer?\n",
      "Options:\n",
      "A oil condition\n",
      "B amps/ volts/ load\n",
      "C ultrasound\n",
      "D noise\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 339, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices can indicate the presence of insulation deterioration in asset electric generator?\\nOptions:\\nA cooling gas\\nB oil debris\\nC temparature\\nD vibration\\nE power\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices can indicate the presence of insulation deterioration in asset electric generator?', 'options_text': ['cooling gas', 'oil debris', 'temparature', 'vibration', 'power'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, what is the non-relevant failure event when the sensor voltage has an abnormal reading?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B unbalance\n",
      "C loss of output power phase\n",
      "D insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 673, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When fluid leakage detects abnormal readings in compressor, which failure mode is the most relevant?\\nOptions:\\nA bearing wear\\nB misalignment\\nC damaged seals\\nD damaged impeller\\nE eccentric impeller\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When fluid leakage detects abnormal readings in compressor, which failure mode is the most relevant?', 'options_text': ['bearing wear', 'misalignment', 'damaged seals', 'damaged impeller', 'eccentric impeller'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor oil debris in aero gas turbine shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A power turbine damage\n",
      "B seal leakage\n",
      "C compressor fouled\n",
      "D fuel filter blockage\n",
      "E bearing wear/ damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices can indicate the presence of loss of output power phase in asset electric generator?\n",
      "Options:\n",
      "A oil debris\n",
      "B torque\n",
      "C power\n",
      "D current\n",
      "E partial discharge\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, what is the key failure mode when fluid leakage has abnormal readings?\n",
      "Options:\n",
      "A misalignment\n",
      "B compressor stall\n",
      "C unbalance\n",
      "D bearing damage\n",
      "E cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 674, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, what is the key failure mode when fluid leakage has abnormal readings?\\nOptions:\\nA misalignment\\nB compressor stall\\nC unbalance\\nD bearing damage\\nE cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, what is the key failure mode when fluid leakage has abnormal readings?', 'options_text': ['misalignment', 'compressor stall', 'unbalance', 'bearing damage', 'cooling system fault'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode is most relevant for compressor if there are abnormal readings from fluid leakage?\n",
      "Options:\n",
      "A compressor stall\n",
      "B valve fault\n",
      "C bearing wear\n",
      "D bearing damage\n",
      "E damaged impeller\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 340, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices can indicate the presence of loss of output power phase in asset electric generator?\\nOptions:\\nA oil debris\\nB torque\\nC power\\nD current\\nE partial discharge\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices can indicate the presence of loss of output power phase in asset electric generator?', 'options_text': ['oil debris', 'torque', 'power', 'current', 'partial discharge'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices can indicate the presence of loss of output power phase in asset electric generator?\n",
      "Options:\n",
      "A voltage\n",
      "B partial discharge\n",
      "C coast down\n",
      "D temparature\n",
      "E radio frequency emissions\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2010, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor oil debris in aero gas turbine shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA power turbine damage\\nB seal leakage\\nC compressor fouled\\nD fuel filter blockage\\nE bearing wear/ damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor oil debris in aero gas turbine shows an abnormal reading, which failure event is insignificant?', 'options_text': ['power turbine damage', 'seal leakage', 'compressor fouled', 'fuel filter blockage', 'bearing wear/ damage'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For aero gas turbine, what is the non-relevant failure event when the sensor oil debris has an abnormal reading?\n",
      "Options:\n",
      "A gear defects\n",
      "B bearing wear/ damage\n",
      "C compressor damaged\n",
      "D combustion chamber holed\n",
      "E seal leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1676, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices does not indicate the presence of low oil level in asset power transformer?\\nOptions:\\nA oil condition\\nB amps/ volts/ load\\nC ultrasound\\nD noise\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices does not indicate the presence of low oil level in asset power transformer?', 'options_text': ['oil condition', 'amps/ volts/ load', 'ultrasound', 'noise', 'temperature'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In power transformer, which sensor among the choices is least useful for detecting low oil level?\n",
      "Options:\n",
      "A oil condition\n",
      "B dissolved gas analysis\n",
      "C visual\n",
      "D noise\n",
      "E partial discharge\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2344, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, what is the non-relevant failure event when the sensor voltage has an abnormal reading?\\nOptions:\\nA brush(es) fault\\nB unbalance\\nC loss of output power phase\\nD insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, what is the non-relevant failure event when the sensor voltage has an abnormal reading?', 'options_text': ['brush(es) fault', 'unbalance', 'loss of output power phase', 'insulation deterioration'], 'true_answer': [False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for electric generator if the sensor voltage exhibits an abnormal reading?\n",
      "Options:\n",
      "A loss of output power phase\n",
      "B brush(es) fault\n",
      "C insulation deterioration\n",
      "D misalignment\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2345, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for electric generator if the sensor voltage exhibits an abnormal reading?\\nOptions:\\nA loss of output power phase\\nB brush(es) fault\\nC insulation deterioration\\nD misalignment\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for electric generator if the sensor voltage exhibits an abnormal reading?', 'options_text': ['loss of output power phase', 'brush(es) fault', 'insulation deterioration', 'misalignment'], 'true_answer': [False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1677, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In power transformer, which sensor among the choices is least useful for detecting low oil level?\\nOptions:\\nA oil condition\\nB dissolved gas analysis\\nC visual\\nD noise\\nE partial discharge\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In power transformer, which sensor among the choices is least useful for detecting low oil level?', 'options_text': ['oil condition', 'dissolved gas analysis', 'visual', 'noise', 'partial discharge'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 675, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode is most relevant for compressor if there are abnormal readings from fluid leakage?\\nOptions:\\nA compressor stall\\nB valve fault\\nC bearing wear\\nD bearing damage\\nE damaged impeller\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode is most relevant for compressor if there are abnormal readings from fluid leakage?', 'options_text': ['compressor stall', 'valve fault', 'bearing wear', 'bearing damage', 'damaged impeller'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 341, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices can indicate the presence of loss of output power phase in asset electric generator?\\nOptions:\\nA voltage\\nB partial discharge\\nC coast down\\nD temparature\\nE radio frequency emissions\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices can indicate the presence of loss of output power phase in asset electric generator?', 'options_text': ['voltage', 'partial discharge', 'coast down', 'temparature', 'radio frequency emissions'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor resistance in electric generator, which failure event is not relevant?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B rotor windings fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices does not indicate the presence of low oil level in asset power transformer?\n",
      "Options:\n",
      "A ultrasound\n",
      "B dissolved gas analysis\n",
      "C oil condition\n",
      "D vibration\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2011, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For aero gas turbine, what is the non-relevant failure event when the sensor oil debris has an abnormal reading?\\nOptions:\\nA gear defects\\nB bearing wear/ damage\\nC compressor damaged\\nD combustion chamber holed\\nE seal leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For aero gas turbine, what is the non-relevant failure event when the sensor oil debris has an abnormal reading?', 'options_text': ['gear defects', 'bearing wear/ damage', 'compressor damaged', 'combustion chamber holed', 'seal leakage'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode should be considered for compressor when abnormal readings is detected by length measurement?\n",
      "Options:\n",
      "A mounting fault\n",
      "B damaged impeller\n",
      "C eccentric impeller\n",
      "D cooling system fault\n",
      "E unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices provides the strongest indication of loss of output power phase in electric generator?\n",
      "Options:\n",
      "A temparature\n",
      "B vibration\n",
      "C coast down\n",
      "D radio frequency emissions\n",
      "E resistance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For aero gas turbine, what is the non-relevant failure event when the sensor oil debris has an abnormal reading?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B bearing wear/ damage\n",
      "C gear defects\n",
      "D burner blocked\n",
      "E compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2012, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For aero gas turbine, what is the non-relevant failure event when the sensor oil debris has an abnormal reading?\\nOptions:\\nA compressor fouled\\nB bearing wear/ damage\\nC gear defects\\nD burner blocked\\nE compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For aero gas turbine, what is the non-relevant failure event when the sensor oil debris has an abnormal reading?', 'options_text': ['compressor fouled', 'bearing wear/ damage', 'gear defects', 'burner blocked', 'compressor damaged'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 676, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode should be considered for compressor when abnormal readings is detected by length measurement?\\nOptions:\\nA mounting fault\\nB damaged impeller\\nC eccentric impeller\\nD cooling system fault\\nE unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode should be considered for compressor when abnormal readings is detected by length measurement?', 'options_text': ['mounting fault', 'damaged impeller', 'eccentric impeller', 'cooling system fault', 'unbalance'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2346, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor resistance in electric generator, which failure event is not relevant?\\nOptions:\\nA insulation deterioration\\nB rotor windings fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor resistance in electric generator, which failure event is not relevant?', 'options_text': ['insulation deterioration', 'rotor windings fault'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1678, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices does not indicate the presence of low oil level in asset power transformer?\\nOptions:\\nA ultrasound\\nB dissolved gas analysis\\nC oil condition\\nD vibration\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices does not indicate the presence of low oil level in asset power transformer?', 'options_text': ['ultrasound', 'dissolved gas analysis', 'oil condition', 'vibration', 'temperature'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor oil debris in aero gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A power turbine dirty\n",
      "B bearing wear/ damage\n",
      "C compressor fouled\n",
      "D gear defects\n",
      "E compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When length measurement detects abnormal readings in compressor, which failure mode is the most relevant?\n",
      "Options:\n",
      "A valve fault\n",
      "B cooling system fault\n",
      "C unbalance\n",
      "D damaged seals\n",
      "E eccentric impeller\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 342, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices provides the strongest indication of loss of output power phase in electric generator?\\nOptions:\\nA temparature\\nB vibration\\nC coast down\\nD radio frequency emissions\\nE resistance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices provides the strongest indication of loss of output power phase in electric generator?', 'options_text': ['temparature', 'vibration', 'coast down', 'radio frequency emissions', 'resistance'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, what is the non-relevant failure event when the sensor resistance has an abnormal reading?\n",
      "Options:\n",
      "A stator windings fault\n",
      "B insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if a failure event low oil level occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A temperature\n",
      "B oil condition\n",
      "C power factor/tanδ\n",
      "D noise\n",
      "E dissolved gas analysis\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with unbalance in electric generator, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A vibration\n",
      "B resistance\n",
      "C power\n",
      "D voltage\n",
      "E partial discharge\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 343, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with unbalance in electric generator, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA vibration\\nB resistance\\nC power\\nD voltage\\nE partial discharge\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with unbalance in electric generator, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['vibration', 'resistance', 'power', 'voltage', 'partial discharge'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 677, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When length measurement detects abnormal readings in compressor, which failure mode is the most relevant?\\nOptions:\\nA valve fault\\nB cooling system fault\\nC unbalance\\nD damaged seals\\nE eccentric impeller\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When length measurement detects abnormal readings in compressor, which failure mode is the most relevant?', 'options_text': ['valve fault', 'cooling system fault', 'unbalance', 'damaged seals', 'eccentric impeller'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1679, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if a failure event low oil level occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\\nOptions:\\nA temperature\\nB oil condition\\nC power factor/tanδ\\nD noise\\nE dissolved gas analysis\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if a failure event low oil level occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?', 'options_text': ['temperature', 'oil condition', 'power factor/tanδ', 'noise', 'dissolved gas analysis'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2347, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, what is the non-relevant failure event when the sensor resistance has an abnormal reading?\\nOptions:\\nA stator windings fault\\nB insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, what is the non-relevant failure event when the sensor resistance has an abnormal reading?', 'options_text': ['stator windings fault', 'insulation deterioration'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 10 / 334 samples completed.\n",
      "INFO:root:One thread 10 / 334 samples completed.\n",
      "INFO:root:One thread 10 / 334 samples completed.\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2013, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor oil debris in aero gas turbine, which failure event is not relevant?\\nOptions:\\nA power turbine dirty\\nB bearing wear/ damage\\nC compressor fouled\\nD gear defects\\nE compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor oil debris in aero gas turbine, which failure event is not relevant?', 'options_text': ['power turbine dirty', 'bearing wear/ damage', 'compressor fouled', 'gear defects', 'compressor damaged'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 10 / 329 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, if a failure event misalignment occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A axial flux\n",
      "B partial discharge\n",
      "C vibration\n",
      "D oil debris\n",
      "E coast down\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When length measurement in compressor displays abnormal readings, which failure mode is the most applicable?\n",
      "Options:\n",
      "A unbalance\n",
      "B mounting fault\n",
      "C bearing damage\n",
      "D valve fault\n",
      "E cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In power transformer, which sensor among the choices is least useful for detecting low oil level?\n",
      "Options:\n",
      "A resistance\n",
      "B dissolved gas analysis\n",
      "C visual\n",
      "D oil condition\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:One thread 10 / 334 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of electric generator, which failure event is not relevant when the sensor resistance shows an abnormal reading?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B eccentric rotor\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event is irrelevant for aero gas turbine if there is an abnormal reading from the sensor oil debris?\n",
      "Options:\n",
      "A unbalance\n",
      "B compressor damaged\n",
      "C power turbine damage\n",
      "D seal leakage\n",
      "E gear defects\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2348, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of electric generator, which failure event is not relevant when the sensor resistance shows an abnormal reading?\\nOptions:\\nA insulation deterioration\\nB eccentric rotor\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of electric generator, which failure event is not relevant when the sensor resistance shows an abnormal reading?', 'options_text': ['insulation deterioration', 'eccentric rotor'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 344, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, if a failure event misalignment occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\\nOptions:\\nA axial flux\\nB partial discharge\\nC vibration\\nD oil debris\\nE coast down\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, if a failure event misalignment occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?', 'options_text': ['axial flux', 'partial discharge', 'vibration', 'oil debris', 'coast down'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, which failure event is not pertinent if the sensor resistance registers an abnormal reading?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1680, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In power transformer, which sensor among the choices is least useful for detecting low oil level?\\nOptions:\\nA resistance\\nB dissolved gas analysis\\nC visual\\nD oil condition\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In power transformer, which sensor among the choices is least useful for detecting low oil level?', 'options_text': ['resistance', 'dissolved gas analysis', 'visual', 'oil condition', 'temperature'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2014, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event is irrelevant for aero gas turbine if there is an abnormal reading from the sensor oil debris?\\nOptions:\\nA unbalance\\nB compressor damaged\\nC power turbine damage\\nD seal leakage\\nE gear defects\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event is irrelevant for aero gas turbine if there is an abnormal reading from the sensor oil debris?', 'options_text': ['unbalance', 'compressor damaged', 'power turbine damage', 'seal leakage', 'gear defects'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 678, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When length measurement in compressor displays abnormal readings, which failure mode is the most applicable?\\nOptions:\\nA unbalance\\nB mounting fault\\nC bearing damage\\nD valve fault\\nE cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When length measurement in compressor displays abnormal readings, which failure mode is the most applicable?', 'options_text': ['unbalance', 'mounting fault', 'bearing damage', 'valve fault', 'cooling system fault'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor among the choices best correlates with the presence of damaged impeller in asset fan?\n",
      "Options:\n",
      "A air leakage\n",
      "B oil leakage\n",
      "C length measurement\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting low oil level in power transformer?\n",
      "Options:\n",
      "A dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "B oil condition\n",
      "C dissolved gas analysis\n",
      "D ultrasound\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For aero gas turbine, which failure event is not pertinent if the sensor oil debris registers an abnormal reading?\n",
      "Options:\n",
      "A compressor damaged\n",
      "B misalignment\n",
      "C seal leakage\n",
      "D power turbine damage\n",
      "E compressor fouled\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, what is the key failure mode when length measurement has abnormal readings?\n",
      "Options:\n",
      "A unbalance\n",
      "B valve fault\n",
      "C cooling system fault\n",
      "D eccentric impeller\n",
      "E bearing wear\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2349, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, which failure event is not pertinent if the sensor resistance registers an abnormal reading?\\nOptions:\\nA brush(es) fault\\nB insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, which failure event is not pertinent if the sensor resistance registers an abnormal reading?', 'options_text': ['brush(es) fault', 'insulation deterioration'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 679, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, what is the key failure mode when length measurement has abnormal readings?\\nOptions:\\nA unbalance\\nB valve fault\\nC cooling system fault\\nD eccentric impeller\\nE bearing wear\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, what is the key failure mode when length measurement has abnormal readings?', 'options_text': ['unbalance', 'valve fault', 'cooling system fault', 'eccentric impeller', 'bearing wear'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2015, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For aero gas turbine, which failure event is not pertinent if the sensor oil debris registers an abnormal reading?\\nOptions:\\nA compressor damaged\\nB misalignment\\nC seal leakage\\nD power turbine damage\\nE compressor fouled\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For aero gas turbine, which failure event is not pertinent if the sensor oil debris registers an abnormal reading?', 'options_text': ['compressor damaged', 'misalignment', 'seal leakage', 'power turbine damage', 'compressor fouled'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1681, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor from the choices does not contribute significantly to detecting low oil level in power transformer?\\nOptions:\\nA dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nB oil condition\\nC dissolved gas analysis\\nD ultrasound\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor from the choices does not contribute significantly to detecting low oil level in power transformer?', 'options_text': ['dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'oil condition', 'dissolved gas analysis', 'ultrasound', 'temperature'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 345, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor among the choices best correlates with the presence of damaged impeller in asset fan?\\nOptions:\\nA air leakage\\nB oil leakage\\nC length measurement\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor among the choices best correlates with the presence of damaged impeller in asset fan?', 'options_text': ['air leakage', 'oil leakage', 'length measurement'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of electric generator, which failure event is not relevant when the sensor resistance shows an abnormal reading?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In compressor, which failure mode is most important if length measurement shows abnormal readings?\n",
      "Options:\n",
      "A valve fault\n",
      "B compressor stall\n",
      "C cooling system fault\n",
      "D eccentric impeller\n",
      "E unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for aero gas turbine when an abnormal reading is detected by the sensor oil leakage/ consumption?\n",
      "Options:\n",
      "A seal leakage\n",
      "B air inlet blockage\n",
      "C bearing wear/ damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices does not indicate the presence of low oil level in asset power transformer?\n",
      "Options:\n",
      "A visual\n",
      "B frequency response analysis (fra)\n",
      "C oil condition\n",
      "D dissolved gas analysis\n",
      "E noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with damaged impeller in fan, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A air leakage\n",
      "B oil leakage\n",
      "C power\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 680, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In compressor, which failure mode is most important if length measurement shows abnormal readings?\\nOptions:\\nA valve fault\\nB compressor stall\\nC cooling system fault\\nD eccentric impeller\\nE unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In compressor, which failure mode is most important if length measurement shows abnormal readings?', 'options_text': ['valve fault', 'compressor stall', 'cooling system fault', 'eccentric impeller', 'unbalance'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 346, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with damaged impeller in fan, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA air leakage\\nB oil leakage\\nC power\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with damaged impeller in fan, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['air leakage', 'oil leakage', 'power'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2350, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of electric generator, which failure event is not relevant when the sensor resistance shows an abnormal reading?\\nOptions:\\nA insulation deterioration\\nB bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of electric generator, which failure event is not relevant when the sensor resistance shows an abnormal reading?', 'options_text': ['insulation deterioration', 'bearing damage'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In compressor, which failure mode is most important if length measurement shows abnormal readings?\n",
      "Options:\n",
      "A unbalance\n",
      "B mounting fault\n",
      "C eccentric impeller\n",
      "D misalignment\n",
      "E cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In fan, when damaged impeller occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\n",
      "Options:\n",
      "A oil leakage\n",
      "B pressure or vacuum\n",
      "C air leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2016, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for aero gas turbine when an abnormal reading is detected by the sensor oil leakage/ consumption?\\nOptions:\\nA seal leakage\\nB air inlet blockage\\nC bearing wear/ damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for aero gas turbine when an abnormal reading is detected by the sensor oil leakage/ consumption?', 'options_text': ['seal leakage', 'air inlet blockage', 'bearing wear/ damage'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, what is the non-relevant failure event when the sensor resistance has an abnormal reading?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B loss of output power phase\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1682, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices does not indicate the presence of low oil level in asset power transformer?\\nOptions:\\nA visual\\nB frequency response analysis (fra)\\nC oil condition\\nD dissolved gas analysis\\nE noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices does not indicate the presence of low oil level in asset power transformer?', 'options_text': ['visual', 'frequency response analysis (fra)', 'oil condition', 'dissolved gas analysis', 'noise'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for aero gas turbine when an abnormal reading is detected by the sensor oil leakage/ consumption?\n",
      "Options:\n",
      "A seal leakage\n",
      "B compressor fouled\n",
      "C bearing wear/ damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a power transformer has low oil level, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A ultrasound\n",
      "B noise\n",
      "C oil condition\n",
      "D temperature\n",
      "E excitation current\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1683, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a power transformer has low oil level, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA ultrasound\\nB noise\\nC oil condition\\nD temperature\\nE excitation current\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a power transformer has low oil level, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['ultrasound', 'noise', 'oil condition', 'temperature', 'excitation current'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 347, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In fan, when damaged impeller occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\\nOptions:\\nA oil leakage\\nB pressure or vacuum\\nC air leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In fan, when damaged impeller occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?', 'options_text': ['oil leakage', 'pressure or vacuum', 'air leakage'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of low oil level in power transformer?\n",
      "Options:\n",
      "A visual\n",
      "B oil condition\n",
      "C leak reactance flux\n",
      "D noise\n",
      "E ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In fan, when damaged impeller occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\n",
      "Options:\n",
      "A oil leakage\n",
      "B air leakage\n",
      "C speed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2017, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for aero gas turbine when an abnormal reading is detected by the sensor oil leakage/ consumption?\\nOptions:\\nA seal leakage\\nB compressor fouled\\nC bearing wear/ damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for aero gas turbine when an abnormal reading is detected by the sensor oil leakage/ consumption?', 'options_text': ['seal leakage', 'compressor fouled', 'bearing wear/ damage'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 681, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In compressor, which failure mode is most important if length measurement shows abnormal readings?\\nOptions:\\nA unbalance\\nB mounting fault\\nC eccentric impeller\\nD misalignment\\nE cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In compressor, which failure mode is most important if length measurement shows abnormal readings?', 'options_text': ['unbalance', 'mounting fault', 'eccentric impeller', 'misalignment', 'cooling system fault'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2351, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, what is the non-relevant failure event when the sensor resistance has an abnormal reading?\\nOptions:\\nA insulation deterioration\\nB loss of output power phase\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, what is the non-relevant failure event when the sensor resistance has an abnormal reading?', 'options_text': ['insulation deterioration', 'loss of output power phase'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor oil leakage/ consumption in aero gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A compressor damaged\n",
      "B bearing wear/ damage\n",
      "C seal leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When power in compressor displays abnormal readings, which failure mode is the most applicable?\n",
      "Options:\n",
      "A damaged seals\n",
      "B mounting fault\n",
      "C damaged impeller\n",
      "D valve fault\n",
      "E cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, what is the non-relevant failure event when the sensor resistance has an abnormal reading?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2018, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor oil leakage/ consumption in aero gas turbine, which failure event is not relevant?\\nOptions:\\nA compressor damaged\\nB bearing wear/ damage\\nC seal leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor oil leakage/ consumption in aero gas turbine, which failure event is not relevant?', 'options_text': ['compressor damaged', 'bearing wear/ damage', 'seal leakage'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2352, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, what is the non-relevant failure event when the sensor resistance has an abnormal reading?\\nOptions:\\nA insulation deterioration\\nB unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, what is the non-relevant failure event when the sensor resistance has an abnormal reading?', 'options_text': ['insulation deterioration', 'unbalance'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 682, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When power in compressor displays abnormal readings, which failure mode is the most applicable?\\nOptions:\\nA damaged seals\\nB mounting fault\\nC damaged impeller\\nD valve fault\\nE cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When power in compressor displays abnormal readings, which failure mode is the most applicable?', 'options_text': ['damaged seals', 'mounting fault', 'damaged impeller', 'valve fault', 'cooling system fault'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1684, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of low oil level in power transformer?\\nOptions:\\nA visual\\nB oil condition\\nC leak reactance flux\\nD noise\\nE ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of low oil level in power transformer?', 'options_text': ['visual', 'oil condition', 'leak reactance flux', 'noise', 'ultrasound'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of aero gas turbine, which failure event is not relevant when the sensor oil leakage/ consumption shows an abnormal reading?\n",
      "Options:\n",
      "A seal leakage\n",
      "B bearing wear/ damage\n",
      "C compressor stall\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor resistance in electric generator shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A misalignment\n",
      "B insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 348, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In fan, when damaged impeller occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\\nOptions:\\nA oil leakage\\nB air leakage\\nC speed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In fan, when damaged impeller occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?', 'options_text': ['oil leakage', 'air leakage', 'speed'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode should be considered for compressor when abnormal readings is detected by power?\n",
      "Options:\n",
      "A valve fault\n",
      "B eccentric impeller\n",
      "C compressor stall\n",
      "D mounting fault\n",
      "E bearing wear\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of low oil level in power transformer?\n",
      "Options:\n",
      "A temperature\n",
      "B noise\n",
      "C oil condition\n",
      "D bushing capacitance\n",
      "E ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a fan has damaged impeller, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A vibration\n",
      "B air leakage\n",
      "C oil leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1685, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of low oil level in power transformer?\\nOptions:\\nA temperature\\nB noise\\nC oil condition\\nD bushing capacitance\\nE ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of low oil level in power transformer?', 'options_text': ['temperature', 'noise', 'oil condition', 'bushing capacitance', 'ultrasound'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 683, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode should be considered for compressor when abnormal readings is detected by power?\\nOptions:\\nA valve fault\\nB eccentric impeller\\nC compressor stall\\nD mounting fault\\nE bearing wear\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode should be considered for compressor when abnormal readings is detected by power?', 'options_text': ['valve fault', 'eccentric impeller', 'compressor stall', 'mounting fault', 'bearing wear'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 349, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a fan has damaged impeller, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA vibration\\nB air leakage\\nC oil leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a fan has damaged impeller, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['vibration', 'air leakage', 'oil leakage'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2353, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor resistance in electric generator shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA misalignment\\nB insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor resistance in electric generator shows an abnormal reading, which failure event is insignificant?', 'options_text': ['misalignment', 'insulation deterioration'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2019, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of aero gas turbine, which failure event is not relevant when the sensor oil leakage/ consumption shows an abnormal reading?\\nOptions:\\nA seal leakage\\nB bearing wear/ damage\\nC compressor stall\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of aero gas turbine, which failure event is not relevant when the sensor oil leakage/ consumption shows an abnormal reading?', 'options_text': ['seal leakage', 'bearing wear/ damage', 'compressor stall'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In power transformer, which sensor among the choices is least useful for detecting oil circulation system problem?\n",
      "Options:\n",
      "A visual\n",
      "B amps/ volts/ load\n",
      "C temperature\n",
      "D dissolved gas analysis\n",
      "E oil condition\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, what is the key failure mode when power has abnormal readings?\n",
      "Options:\n",
      "A bearing damage\n",
      "B mounting fault\n",
      "C unbalance\n",
      "D damaged seals\n",
      "E bearing wear\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices can indicate the presence of damaged impeller in asset fan?\n",
      "Options:\n",
      "A air leakage\n",
      "B oil leakage\n",
      "C temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor partial discharge in electric generator shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B rotor windings fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor oil leakage/ consumption in aero gas turbine displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A bearing wear/ damage\n",
      "B seal leakage\n",
      "C fuel filter blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1686, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In power transformer, which sensor among the choices is least useful for detecting oil circulation system problem?\\nOptions:\\nA visual\\nB amps/ volts/ load\\nC temperature\\nD dissolved gas analysis\\nE oil condition\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In power transformer, which sensor among the choices is least useful for detecting oil circulation system problem?', 'options_text': ['visual', 'amps/ volts/ load', 'temperature', 'dissolved gas analysis', 'oil condition'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 684, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, what is the key failure mode when power has abnormal readings?\\nOptions:\\nA bearing damage\\nB mounting fault\\nC unbalance\\nD damaged seals\\nE bearing wear\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, what is the key failure mode when power has abnormal readings?', 'options_text': ['bearing damage', 'mounting fault', 'unbalance', 'damaged seals', 'bearing wear'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2354, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor partial discharge in electric generator shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA insulation deterioration\\nB rotor windings fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor partial discharge in electric generator shows an abnormal reading, which failure event is insignificant?', 'options_text': ['insulation deterioration', 'rotor windings fault'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 350, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices can indicate the presence of damaged impeller in asset fan?\\nOptions:\\nA air leakage\\nB oil leakage\\nC temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices can indicate the presence of damaged impeller in asset fan?', 'options_text': ['air leakage', 'oil leakage', 'temperature'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if a failure event oil circulation system problem occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A visual\n",
      "B temperature\n",
      "C dissolved gas analysis\n",
      "D oil condition\n",
      "E partial discharge\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2020, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor oil leakage/ consumption in aero gas turbine displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA bearing wear/ damage\\nB seal leakage\\nC fuel filter blockage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor oil leakage/ consumption in aero gas turbine displays an abnormal reading, which failure event is not applicable?', 'options_text': ['bearing wear/ damage', 'seal leakage', 'fuel filter blockage'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode is most relevant for compressor if there are abnormal readings from pressure or vacuum?\n",
      "Options:\n",
      "A compressor stall\n",
      "B misalignment\n",
      "C damaged impeller\n",
      "D unbalance\n",
      "E bearing wear\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor partial discharge in electric generator, which failure event is not relevant?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B stator windings fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices can indicate the presence of damaged impeller in asset fan?\n",
      "Options:\n",
      "A air leakage\n",
      "B coast down time\n",
      "C oil leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In aero gas turbine, which failure event is unimportant if the sensor oil leakage/ consumption shows an abnormal reading?\n",
      "Options:\n",
      "A seal leakage\n",
      "B bearing wear/ damage\n",
      "C combustion chamber holed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2021, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In aero gas turbine, which failure event is unimportant if the sensor oil leakage/ consumption shows an abnormal reading?\\nOptions:\\nA seal leakage\\nB bearing wear/ damage\\nC combustion chamber holed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In aero gas turbine, which failure event is unimportant if the sensor oil leakage/ consumption shows an abnormal reading?', 'options_text': ['seal leakage', 'bearing wear/ damage', 'combustion chamber holed'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 351, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices can indicate the presence of damaged impeller in asset fan?\\nOptions:\\nA air leakage\\nB coast down time\\nC oil leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices can indicate the presence of damaged impeller in asset fan?', 'options_text': ['air leakage', 'coast down time', 'oil leakage'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2355, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor partial discharge in electric generator, which failure event is not relevant?\\nOptions:\\nA insulation deterioration\\nB stator windings fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor partial discharge in electric generator, which failure event is not relevant?', 'options_text': ['insulation deterioration', 'stator windings fault'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1687, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if a failure event oil circulation system problem occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\\nOptions:\\nA visual\\nB temperature\\nC dissolved gas analysis\\nD oil condition\\nE partial discharge\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if a failure event oil circulation system problem occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?', 'options_text': ['visual', 'temperature', 'dissolved gas analysis', 'oil condition', 'partial discharge'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 685, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode is most relevant for compressor if there are abnormal readings from pressure or vacuum?\\nOptions:\\nA compressor stall\\nB misalignment\\nC damaged impeller\\nD unbalance\\nE bearing wear\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode is most relevant for compressor if there are abnormal readings from pressure or vacuum?', 'options_text': ['compressor stall', 'misalignment', 'damaged impeller', 'unbalance', 'bearing wear'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor oil leakage/ consumption in aero gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A bearing wear/ damage\n",
      "B seal leakage\n",
      "C burner blocked\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For fan, if a failure event damaged impeller occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A oil debris\n",
      "B air leakage\n",
      "C oil leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In electric generator, which failure event is unimportant if the sensor partial discharge shows an abnormal reading?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B eccentric rotor\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting oil circulation system problem in power transformer?\n",
      "Options:\n",
      "A temperature\n",
      "B noise\n",
      "C dissolved gas analysis\n",
      "D oil condition\n",
      "E visual\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, which failure mode is pertinent if pressure or vacuum registers abnormal readings?\n",
      "Options:\n",
      "A damaged seals\n",
      "B bearing wear\n",
      "C bearing damage\n",
      "D unbalance\n",
      "E mounting fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1688, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor from the choices does not contribute significantly to detecting oil circulation system problem in power transformer?\\nOptions:\\nA temperature\\nB noise\\nC dissolved gas analysis\\nD oil condition\\nE visual\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor from the choices does not contribute significantly to detecting oil circulation system problem in power transformer?', 'options_text': ['temperature', 'noise', 'dissolved gas analysis', 'oil condition', 'visual'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 352, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For fan, if a failure event damaged impeller occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\\nOptions:\\nA oil debris\\nB air leakage\\nC oil leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For fan, if a failure event damaged impeller occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?', 'options_text': ['oil debris', 'air leakage', 'oil leakage'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if a failure event oil circulation system problem occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A dissolved gas analysis\n",
      "B oil condition\n",
      "C ultrasound\n",
      "D temperature\n",
      "E visual\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 686, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, which failure mode is pertinent if pressure or vacuum registers abnormal readings?\\nOptions:\\nA damaged seals\\nB bearing wear\\nC bearing damage\\nD unbalance\\nE mounting fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, which failure mode is pertinent if pressure or vacuum registers abnormal readings?', 'options_text': ['damaged seals', 'bearing wear', 'bearing damage', 'unbalance', 'mounting fault'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor among the choices best correlates with the presence of damaged oil seals in asset fan?\n",
      "Options:\n",
      "A temperature\n",
      "B length measurement\n",
      "C air leakage\n",
      "D coast down time\n",
      "E power\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2022, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor oil leakage/ consumption in aero gas turbine, which failure event is not relevant?\\nOptions:\\nA bearing wear/ damage\\nB seal leakage\\nC burner blocked\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor oil leakage/ consumption in aero gas turbine, which failure event is not relevant?', 'options_text': ['bearing wear/ damage', 'seal leakage', 'burner blocked'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2356, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In electric generator, which failure event is unimportant if the sensor partial discharge shows an abnormal reading?\\nOptions:\\nA insulation deterioration\\nB eccentric rotor\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In electric generator, which failure event is unimportant if the sensor partial discharge shows an abnormal reading?', 'options_text': ['insulation deterioration', 'eccentric rotor'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If pressure or vacuum in compressor shows abnormal readings, which failure mode is most significant?\n",
      "Options:\n",
      "A bearing damage\n",
      "B bearing wear\n",
      "C unbalance\n",
      "D misalignment\n",
      "E eccentric impeller\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor oil leakage/ consumption in aero gas turbine displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A seal leakage\n",
      "B bearing wear/ damage\n",
      "C power turbine dirty\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for electric generator if the sensor partial discharge exhibits an abnormal reading?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1689, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if a failure event oil circulation system problem occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\\nOptions:\\nA dissolved gas analysis\\nB oil condition\\nC ultrasound\\nD temperature\\nE visual\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if a failure event oil circulation system problem occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?', 'options_text': ['dissolved gas analysis', 'oil condition', 'ultrasound', 'temperature', 'visual'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2023, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor oil leakage/ consumption in aero gas turbine displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA seal leakage\\nB bearing wear/ damage\\nC power turbine dirty\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor oil leakage/ consumption in aero gas turbine displays an abnormal reading, which failure event is not applicable?', 'options_text': ['seal leakage', 'bearing wear/ damage', 'power turbine dirty'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2357, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for electric generator if the sensor partial discharge exhibits an abnormal reading?\\nOptions:\\nA brush(es) fault\\nB insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for electric generator if the sensor partial discharge exhibits an abnormal reading?', 'options_text': ['brush(es) fault', 'insulation deterioration'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 687, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If pressure or vacuum in compressor shows abnormal readings, which failure mode is most significant?\\nOptions:\\nA bearing damage\\nB bearing wear\\nC unbalance\\nD misalignment\\nE eccentric impeller\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If pressure or vacuum in compressor shows abnormal readings, which failure mode is most significant?', 'options_text': ['bearing damage', 'bearing wear', 'unbalance', 'misalignment', 'eccentric impeller'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 20 / 334 samples completed.\n",
      "INFO:root:One thread 20 / 334 samples completed.\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 353, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor among the choices best correlates with the presence of damaged oil seals in asset fan?\\nOptions:\\nA temperature\\nB length measurement\\nC air leakage\\nD coast down time\\nE power\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor among the choices best correlates with the presence of damaged oil seals in asset fan?', 'options_text': ['temperature', 'length measurement', 'air leakage', 'coast down time', 'power'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 20 / 329 samples completed.\n",
      "INFO:root:One thread 20 / 334 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting oil circulation system problem in power transformer?\n",
      "Options:\n",
      "A visual\n",
      "B dissolved gas analysis\n",
      "C vibration\n",
      "D oil condition\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For aero gas turbine, which failure event is not pertinent if the sensor oil leakage/ consumption registers an abnormal reading?\n",
      "Options:\n",
      "A seal leakage\n",
      "B bearing wear/ damage\n",
      "C power turbine damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:One thread 20 / 334 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for electric generator if the sensor partial discharge exhibits an abnormal reading?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode is most relevant for compressor if there are abnormal readings from pressure or vacuum?\n",
      "Options:\n",
      "A cooling system fault\n",
      "B bearing wear\n",
      "C mounting fault\n",
      "D unbalance\n",
      "E bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with damaged oil seals in fan, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A pressure or vacuum\n",
      "B temperature\n",
      "C vibration\n",
      "D power\n",
      "E air leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1690, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor from the choices does not contribute significantly to detecting oil circulation system problem in power transformer?\\nOptions:\\nA visual\\nB dissolved gas analysis\\nC vibration\\nD oil condition\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor from the choices does not contribute significantly to detecting oil circulation system problem in power transformer?', 'options_text': ['visual', 'dissolved gas analysis', 'vibration', 'oil condition', 'temperature'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if a failure event oil circulation system problem occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A power factor/tanδ\n",
      "B temperature\n",
      "C oil condition\n",
      "D visual\n",
      "E dissolved gas analysis\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 688, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode is most relevant for compressor if there are abnormal readings from pressure or vacuum?\\nOptions:\\nA cooling system fault\\nB bearing wear\\nC mounting fault\\nD unbalance\\nE bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode is most relevant for compressor if there are abnormal readings from pressure or vacuum?', 'options_text': ['cooling system fault', 'bearing wear', 'mounting fault', 'unbalance', 'bearing damage'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 354, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with damaged oil seals in fan, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA pressure or vacuum\\nB temperature\\nC vibration\\nD power\\nE air leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with damaged oil seals in fan, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['pressure or vacuum', 'temperature', 'vibration', 'power', 'air leakage'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2024, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For aero gas turbine, which failure event is not pertinent if the sensor oil leakage/ consumption registers an abnormal reading?\\nOptions:\\nA seal leakage\\nB bearing wear/ damage\\nC power turbine damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For aero gas turbine, which failure event is not pertinent if the sensor oil leakage/ consumption registers an abnormal reading?', 'options_text': ['seal leakage', 'bearing wear/ damage', 'power turbine damage'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2358, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for electric generator if the sensor partial discharge exhibits an abnormal reading?\\nOptions:\\nA insulation deterioration\\nB bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for electric generator if the sensor partial discharge exhibits an abnormal reading?', 'options_text': ['insulation deterioration', 'bearing damage'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode is most relevant for compressor if there are abnormal readings from pressure or vacuum?\n",
      "Options:\n",
      "A valve fault\n",
      "B misalignment\n",
      "C mounting fault\n",
      "D bearing wear\n",
      "E compressor stall\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with damaged oil seals in fan, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A power\n",
      "B vibration\n",
      "C coast down time\n",
      "D air leakage\n",
      "E speed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor oil leakage/ consumption in aero gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A gear defects\n",
      "B seal leakage\n",
      "C bearing wear/ damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In electric generator, which failure event is unimportant if the sensor partial discharge shows an abnormal reading?\n",
      "Options:\n",
      "A loss of output power phase\n",
      "B insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2359, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In electric generator, which failure event is unimportant if the sensor partial discharge shows an abnormal reading?\\nOptions:\\nA loss of output power phase\\nB insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In electric generator, which failure event is unimportant if the sensor partial discharge shows an abnormal reading?', 'options_text': ['loss of output power phase', 'insulation deterioration'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1691, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if a failure event oil circulation system problem occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\\nOptions:\\nA power factor/tanδ\\nB temperature\\nC oil condition\\nD visual\\nE dissolved gas analysis\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if a failure event oil circulation system problem occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?', 'options_text': ['power factor/tanδ', 'temperature', 'oil condition', 'visual', 'dissolved gas analysis'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 689, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode is most relevant for compressor if there are abnormal readings from pressure or vacuum?\\nOptions:\\nA valve fault\\nB misalignment\\nC mounting fault\\nD bearing wear\\nE compressor stall\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode is most relevant for compressor if there are abnormal readings from pressure or vacuum?', 'options_text': ['valve fault', 'misalignment', 'mounting fault', 'bearing wear', 'compressor stall'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2025, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor oil leakage/ consumption in aero gas turbine, which failure event is not relevant?\\nOptions:\\nA gear defects\\nB seal leakage\\nC bearing wear/ damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor oil leakage/ consumption in aero gas turbine, which failure event is not relevant?', 'options_text': ['gear defects', 'seal leakage', 'bearing wear/ damage'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for electric generator if the sensor partial discharge exhibits an abnormal reading?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting oil circulation system problem in power transformer?\n",
      "Options:\n",
      "A resistance\n",
      "B dissolved gas analysis\n",
      "C oil condition\n",
      "D temperature\n",
      "E visual\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, which failure mode is pertinent if speed registers abnormal readings?\n",
      "Options:\n",
      "A valve fault\n",
      "B misalignment\n",
      "C damaged impeller\n",
      "D mounting fault\n",
      "E unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 355, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with damaged oil seals in fan, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA power\\nB vibration\\nC coast down time\\nD air leakage\\nE speed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with damaged oil seals in fan, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['power', 'vibration', 'coast down time', 'air leakage', 'speed'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For aero gas turbine, what is the non-relevant failure event when the sensor oil leakage/ consumption has an abnormal reading?\n",
      "Options:\n",
      "A unbalance\n",
      "B bearing wear/ damage\n",
      "C seal leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices provides the strongest indication of damaged oil seals in fan?\n",
      "Options:\n",
      "A vibration\n",
      "B coast down time\n",
      "C oil debris\n",
      "D temperature\n",
      "E air leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 356, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices provides the strongest indication of damaged oil seals in fan?\\nOptions:\\nA vibration\\nB coast down time\\nC oil debris\\nD temperature\\nE air leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices provides the strongest indication of damaged oil seals in fan?', 'options_text': ['vibration', 'coast down time', 'oil debris', 'temperature', 'air leakage'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with damaged oil seals in fan, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A temperature\n",
      "B vibration\n",
      "C oil leakage\n",
      "D power\n",
      "E coast down time\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 690, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, which failure mode is pertinent if speed registers abnormal readings?\\nOptions:\\nA valve fault\\nB misalignment\\nC damaged impeller\\nD mounting fault\\nE unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, which failure mode is pertinent if speed registers abnormal readings?', 'options_text': ['valve fault', 'misalignment', 'damaged impeller', 'mounting fault', 'unbalance'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2026, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For aero gas turbine, what is the non-relevant failure event when the sensor oil leakage/ consumption has an abnormal reading?\\nOptions:\\nA unbalance\\nB bearing wear/ damage\\nC seal leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For aero gas turbine, what is the non-relevant failure event when the sensor oil leakage/ consumption has an abnormal reading?', 'options_text': ['unbalance', 'bearing wear/ damage', 'seal leakage'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2360, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for electric generator if the sensor partial discharge exhibits an abnormal reading?\\nOptions:\\nA insulation deterioration\\nB unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for electric generator if the sensor partial discharge exhibits an abnormal reading?', 'options_text': ['insulation deterioration', 'unbalance'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1692, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor from the choices does not contribute significantly to detecting oil circulation system problem in power transformer?\\nOptions:\\nA resistance\\nB dissolved gas analysis\\nC oil condition\\nD temperature\\nE visual\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor from the choices does not contribute significantly to detecting oil circulation system problem in power transformer?', 'options_text': ['resistance', 'dissolved gas analysis', 'oil condition', 'temperature', 'visual'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the most relevant failure mode for compressor if speed exhibits abnormal readings?\n",
      "Options:\n",
      "A misalignment\n",
      "B mounting fault\n",
      "C damaged seals\n",
      "D bearing wear\n",
      "E unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For aero gas turbine, which failure event is not pertinent if the sensor oil leakage/ consumption registers an abnormal reading?\n",
      "Options:\n",
      "A seal leakage\n",
      "B bearing wear/ damage\n",
      "C misalignment\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In electric generator, which failure event is unimportant if the sensor partial discharge shows an abnormal reading?\n",
      "Options:\n",
      "A misalignment\n",
      "B insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if oil circulation system problem occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\n",
      "Options:\n",
      "A dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "B temperature\n",
      "C oil condition\n",
      "D visual\n",
      "E dissolved gas analysis\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2361, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In electric generator, which failure event is unimportant if the sensor partial discharge shows an abnormal reading?\\nOptions:\\nA misalignment\\nB insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In electric generator, which failure event is unimportant if the sensor partial discharge shows an abnormal reading?', 'options_text': ['misalignment', 'insulation deterioration'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 691, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the most relevant failure mode for compressor if speed exhibits abnormal readings?\\nOptions:\\nA misalignment\\nB mounting fault\\nC damaged seals\\nD bearing wear\\nE unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the most relevant failure mode for compressor if speed exhibits abnormal readings?', 'options_text': ['misalignment', 'mounting fault', 'damaged seals', 'bearing wear', 'unbalance'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1693, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if oil circulation system problem occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\\nOptions:\\nA dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nB temperature\\nC oil condition\\nD visual\\nE dissolved gas analysis\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if oil circulation system problem occurs, which sensor among the choices is least likely to be relevant in identifying this failure?', 'options_text': ['dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'temperature', 'oil condition', 'visual', 'dissolved gas analysis'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, which failure event is not pertinent if the sensor power registers an abnormal reading?\n",
      "Options:\n",
      "A rotor windings fault\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2027, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For aero gas turbine, which failure event is not pertinent if the sensor oil leakage/ consumption registers an abnormal reading?\\nOptions:\\nA seal leakage\\nB bearing wear/ damage\\nC misalignment\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For aero gas turbine, which failure event is not pertinent if the sensor oil leakage/ consumption registers an abnormal reading?', 'options_text': ['seal leakage', 'bearing wear/ damage', 'misalignment'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, which failure mode is pertinent if speed registers abnormal readings?\n",
      "Options:\n",
      "A eccentric impeller\n",
      "B valve fault\n",
      "C bearing wear\n",
      "D unbalance\n",
      "E misalignment\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 357, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with damaged oil seals in fan, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA temperature\\nB vibration\\nC oil leakage\\nD power\\nE coast down time\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with damaged oil seals in fan, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['temperature', 'vibration', 'oil leakage', 'power', 'coast down time'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a power transformer has oil circulation system problem, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A frequency response analysis (fra)\n",
      "B dissolved gas analysis\n",
      "C temperature\n",
      "D visual\n",
      "E oil condition\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor compressor temperature in industrial gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A air inlet blockage\n",
      "B compressor fouled\n",
      "C compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a fan has damaged bellows, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A air leakage\n",
      "B speed\n",
      "C oil leakage\n",
      "D length measurement\n",
      "E pressure or vacuum\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1694, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a power transformer has oil circulation system problem, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA frequency response analysis (fra)\\nB dissolved gas analysis\\nC temperature\\nD visual\\nE oil condition\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a power transformer has oil circulation system problem, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['frequency response analysis (fra)', 'dissolved gas analysis', 'temperature', 'visual', 'oil condition'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 692, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, which failure mode is pertinent if speed registers abnormal readings?\\nOptions:\\nA eccentric impeller\\nB valve fault\\nC bearing wear\\nD unbalance\\nE misalignment\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, which failure mode is pertinent if speed registers abnormal readings?', 'options_text': ['eccentric impeller', 'valve fault', 'bearing wear', 'unbalance', 'misalignment'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 358, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a fan has damaged bellows, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA air leakage\\nB speed\\nC oil leakage\\nD length measurement\\nE pressure or vacuum\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a fan has damaged bellows, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['air leakage', 'speed', 'oil leakage', 'length measurement', 'pressure or vacuum'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2028, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor compressor temperature in industrial gas turbine, which failure event is not relevant?\\nOptions:\\nA air inlet blockage\\nB compressor fouled\\nC compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor compressor temperature in industrial gas turbine, which failure event is not relevant?', 'options_text': ['air inlet blockage', 'compressor fouled', 'compressor damaged'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if oil circulation system problem occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\n",
      "Options:\n",
      "A excitation current\n",
      "B dissolved gas analysis\n",
      "C visual\n",
      "D oil condition\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2362, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, which failure event is not pertinent if the sensor power registers an abnormal reading?\\nOptions:\\nA rotor windings fault\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, which failure event is not pertinent if the sensor power registers an abnormal reading?', 'options_text': ['rotor windings fault', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If speed in compressor shows abnormal readings, which failure mode is most significant?\n",
      "Options:\n",
      "A unbalance\n",
      "B cooling system fault\n",
      "C mounting fault\n",
      "D bearing damage\n",
      "E valve fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices provides the strongest indication of eccentric impeller in fan?\n",
      "Options:\n",
      "A oil debris\n",
      "B air leakage\n",
      "C power\n",
      "D length measurement\n",
      "E oil leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor compressor temperature in industrial gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A compressor damaged\n",
      "B fuel filter blockage\n",
      "C compressor fouled\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In electric generator, which failure event is unimportant if the sensor power shows an abnormal reading?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B stator windings fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2363, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In electric generator, which failure event is unimportant if the sensor power shows an abnormal reading?\\nOptions:\\nA brush(es) fault\\nB stator windings fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In electric generator, which failure event is unimportant if the sensor power shows an abnormal reading?', 'options_text': ['brush(es) fault', 'stator windings fault'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2029, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor compressor temperature in industrial gas turbine, which failure event is not relevant?\\nOptions:\\nA compressor damaged\\nB fuel filter blockage\\nC compressor fouled\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor compressor temperature in industrial gas turbine, which failure event is not relevant?', 'options_text': ['compressor damaged', 'fuel filter blockage', 'compressor fouled'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor power in electric generator, which failure event is not relevant?\n",
      "Options:\n",
      "A eccentric rotor\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 693, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If speed in compressor shows abnormal readings, which failure mode is most significant?\\nOptions:\\nA unbalance\\nB cooling system fault\\nC mounting fault\\nD bearing damage\\nE valve fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If speed in compressor shows abnormal readings, which failure mode is most significant?', 'options_text': ['unbalance', 'cooling system fault', 'mounting fault', 'bearing damage', 'valve fault'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor compressor temperature in industrial gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B combustion chamber holed\n",
      "C compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1695, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if oil circulation system problem occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\\nOptions:\\nA excitation current\\nB dissolved gas analysis\\nC visual\\nD oil condition\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if oil circulation system problem occurs, which sensor among the choices is least likely to be relevant in identifying this failure?', 'options_text': ['excitation current', 'dissolved gas analysis', 'visual', 'oil condition', 'temperature'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 359, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices provides the strongest indication of eccentric impeller in fan?\\nOptions:\\nA oil debris\\nB air leakage\\nC power\\nD length measurement\\nE oil leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices provides the strongest indication of eccentric impeller in fan?', 'options_text': ['oil debris', 'air leakage', 'power', 'length measurement', 'oil leakage'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If speed in compressor shows abnormal readings, which failure mode is most significant?\n",
      "Options:\n",
      "A unbalance\n",
      "B misalignment\n",
      "C valve fault\n",
      "D compressor stall\n",
      "E cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a power transformer has oil circulation system problem, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A dissolved gas analysis\n",
      "B temperature\n",
      "C oil condition\n",
      "D visual\n",
      "E leak reactance flux\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor among the choices best correlates with the presence of eccentric impeller in asset fan?\n",
      "Options:\n",
      "A length measurement\n",
      "B oil leakage\n",
      "C pressure or vacuum\n",
      "D air leakage\n",
      "E oil debris\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1696, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a power transformer has oil circulation system problem, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA dissolved gas analysis\\nB temperature\\nC oil condition\\nD visual\\nE leak reactance flux\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a power transformer has oil circulation system problem, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['dissolved gas analysis', 'temperature', 'oil condition', 'visual', 'leak reactance flux'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2364, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor power in electric generator, which failure event is not relevant?\\nOptions:\\nA eccentric rotor\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor power in electric generator, which failure event is not relevant?', 'options_text': ['eccentric rotor', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if oil circulation system problem occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\n",
      "Options:\n",
      "A dissolved gas analysis\n",
      "B temperature\n",
      "C oil condition\n",
      "D visual\n",
      "E bushing capacitance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 360, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor among the choices best correlates with the presence of eccentric impeller in asset fan?\\nOptions:\\nA length measurement\\nB oil leakage\\nC pressure or vacuum\\nD air leakage\\nE oil debris\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor among the choices best correlates with the presence of eccentric impeller in asset fan?', 'options_text': ['length measurement', 'oil leakage', 'pressure or vacuum', 'air leakage', 'oil debris'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In electric generator, which failure event is unimportant if the sensor power shows an abnormal reading?\n",
      "Options:\n",
      "A bearing damage\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 694, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If speed in compressor shows abnormal readings, which failure mode is most significant?\\nOptions:\\nA unbalance\\nB misalignment\\nC valve fault\\nD compressor stall\\nE cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If speed in compressor shows abnormal readings, which failure mode is most significant?', 'options_text': ['unbalance', 'misalignment', 'valve fault', 'compressor stall', 'cooling system fault'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2030, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor compressor temperature in industrial gas turbine, which failure event is not relevant?\\nOptions:\\nA compressor fouled\\nB combustion chamber holed\\nC compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor compressor temperature in industrial gas turbine, which failure event is not relevant?', 'options_text': ['compressor fouled', 'combustion chamber holed', 'compressor damaged'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a fan has eccentric impeller, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A speed\n",
      "B air leakage\n",
      "C oil debris\n",
      "D oil leakage\n",
      "E length measurement\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode should be considered for compressor when abnormal readings is detected by vibration?\n",
      "Options:\n",
      "A damaged impeller\n",
      "B damaged seals\n",
      "C cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor compressor temperature?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B burner blocked\n",
      "C compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2365, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In electric generator, which failure event is unimportant if the sensor power shows an abnormal reading?\\nOptions:\\nA bearing damage\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In electric generator, which failure event is unimportant if the sensor power shows an abnormal reading?', 'options_text': ['bearing damage', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 695, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode should be considered for compressor when abnormal readings is detected by vibration?\\nOptions:\\nA damaged impeller\\nB damaged seals\\nC cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode should be considered for compressor when abnormal readings is detected by vibration?', 'options_text': ['damaged impeller', 'damaged seals', 'cooling system fault'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1697, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if oil circulation system problem occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\\nOptions:\\nA dissolved gas analysis\\nB temperature\\nC oil condition\\nD visual\\nE bushing capacitance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if oil circulation system problem occurs, which sensor among the choices is least likely to be relevant in identifying this failure?', 'options_text': ['dissolved gas analysis', 'temperature', 'oil condition', 'visual', 'bushing capacitance'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for electric generator if the sensor power exhibits an abnormal reading?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When vibration in compressor displays abnormal readings, which failure mode is the most applicable?\n",
      "Options:\n",
      "A eccentric impeller\n",
      "B damaged seals\n",
      "C cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In power transformer, which sensor among the choices is least useful for detecting winding distortion?\n",
      "Options:\n",
      "A dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "B frequency response analysis (fra)\n",
      "C ultrasound\n",
      "D leak reactance flux\n",
      "E amps/ volts/ load\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2031, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor compressor temperature?\\nOptions:\\nA compressor fouled\\nB burner blocked\\nC compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor compressor temperature?', 'options_text': ['compressor fouled', 'burner blocked', 'compressor damaged'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 361, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a fan has eccentric impeller, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA speed\\nB air leakage\\nC oil debris\\nD oil leakage\\nE length measurement\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a fan has eccentric impeller, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['speed', 'air leakage', 'oil debris', 'oil leakage', 'length measurement'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For industrial gas turbine, what is the non-relevant failure event when the sensor compressor temperature has an abnormal reading?\n",
      "Options:\n",
      "A power turbine damaged\n",
      "B compressor damaged\n",
      "C compressor fouled\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For fan, if a failure event eccentric impeller occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A oil debris\n",
      "B vibration\n",
      "C air leakage\n",
      "D oil leakage\n",
      "E length measurement\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2366, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for electric generator if the sensor power exhibits an abnormal reading?\\nOptions:\\nA brush(es) fault\\nB insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for electric generator if the sensor power exhibits an abnormal reading?', 'options_text': ['brush(es) fault', 'insulation deterioration'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, what is the non-relevant failure event when the sensor power has an abnormal reading?\n",
      "Options:\n",
      "A loss of output power phase\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1698, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In power transformer, which sensor among the choices is least useful for detecting winding distortion?\\nOptions:\\nA dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nB frequency response analysis (fra)\\nC ultrasound\\nD leak reactance flux\\nE amps/ volts/ load\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In power transformer, which sensor among the choices is least useful for detecting winding distortion?', 'options_text': ['dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'frequency response analysis (fra)', 'ultrasound', 'leak reactance flux', 'amps/ volts/ load'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2032, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For industrial gas turbine, what is the non-relevant failure event when the sensor compressor temperature has an abnormal reading?\\nOptions:\\nA power turbine damaged\\nB compressor damaged\\nC compressor fouled\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For industrial gas turbine, what is the non-relevant failure event when the sensor compressor temperature has an abnormal reading?', 'options_text': ['power turbine damaged', 'compressor damaged', 'compressor fouled'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 362, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For fan, if a failure event eccentric impeller occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\\nOptions:\\nA oil debris\\nB vibration\\nC air leakage\\nD oil leakage\\nE length measurement\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For fan, if a failure event eccentric impeller occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?', 'options_text': ['oil debris', 'vibration', 'air leakage', 'oil leakage', 'length measurement'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 696, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When vibration in compressor displays abnormal readings, which failure mode is the most applicable?\\nOptions:\\nA eccentric impeller\\nB damaged seals\\nC cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When vibration in compressor displays abnormal readings, which failure mode is the most applicable?', 'options_text': ['eccentric impeller', 'damaged seals', 'cooling system fault'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of winding distortion in power transformer?\n",
      "Options:\n",
      "A visual\n",
      "B frequency response analysis (fra)\n",
      "C ultrasound\n",
      "D dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "E leak reactance flux\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For industrial gas turbine, which failure event is not pertinent if the sensor compressor temperature registers an abnormal reading?\n",
      "Options:\n",
      "A compressor damaged\n",
      "B bearing wear\n",
      "C compressor fouled\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For fan, if a failure event eccentric impeller occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A air leakage\n",
      "B oil debris\n",
      "C oil leakage\n",
      "D length measurement\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode should be considered for compressor when abnormal readings is detected by vibration?\n",
      "Options:\n",
      "A damaged seals\n",
      "B cooling system fault\n",
      "C bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2367, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, what is the non-relevant failure event when the sensor power has an abnormal reading?\\nOptions:\\nA loss of output power phase\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, what is the non-relevant failure event when the sensor power has an abnormal reading?', 'options_text': ['loss of output power phase', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 363, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For fan, if a failure event eccentric impeller occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\\nOptions:\\nA air leakage\\nB oil debris\\nC oil leakage\\nD length measurement\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For fan, if a failure event eccentric impeller occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?', 'options_text': ['air leakage', 'oil debris', 'oil leakage', 'length measurement', 'temperature'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2033, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For industrial gas turbine, which failure event is not pertinent if the sensor compressor temperature registers an abnormal reading?\\nOptions:\\nA compressor damaged\\nB bearing wear\\nC compressor fouled\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For industrial gas turbine, which failure event is not pertinent if the sensor compressor temperature registers an abnormal reading?', 'options_text': ['compressor damaged', 'bearing wear', 'compressor fouled'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 30 / 329 samples completed.\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 697, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode should be considered for compressor when abnormal readings is detected by vibration?\\nOptions:\\nA damaged seals\\nB cooling system fault\\nC bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode should be considered for compressor when abnormal readings is detected by vibration?', 'options_text': ['damaged seals', 'cooling system fault', 'bearing damage'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 30 / 334 samples completed.\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1699, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of winding distortion in power transformer?\\nOptions:\\nA visual\\nB frequency response analysis (fra)\\nC ultrasound\\nD dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nE leak reactance flux\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of winding distortion in power transformer?', 'options_text': ['visual', 'frequency response analysis (fra)', 'ultrasound', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'leak reactance flux'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 30 / 334 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for electric generator if the sensor power exhibits an abnormal reading?\n",
      "Options:\n",
      "A unbalance\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:One thread 30 / 334 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with eccentric impeller in fan, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A coast down time\n",
      "B oil debris\n",
      "C oil leakage\n",
      "D air leakage\n",
      "E length measurement\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:One thread 30 / 334 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor compressor temperature?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B compressor damaged\n",
      "C unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, what is the key failure mode when vibration has abnormal readings?\n",
      "Options:\n",
      "A damaged seals\n",
      "B bearing wear\n",
      "C cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When considering winding distortion in power transformer, which sensor should be disregarded from the choices for monitoring this failure?\n",
      "Options:\n",
      "A oil condition\n",
      "B ultrasound\n",
      "C frequency response analysis (fra)\n",
      "D dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "E leak reactance flux\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2368, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for electric generator if the sensor power exhibits an abnormal reading?\\nOptions:\\nA unbalance\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for electric generator if the sensor power exhibits an abnormal reading?', 'options_text': ['unbalance', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 364, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with eccentric impeller in fan, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA coast down time\\nB oil debris\\nC oil leakage\\nD air leakage\\nE length measurement\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with eccentric impeller in fan, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['coast down time', 'oil debris', 'oil leakage', 'air leakage', 'length measurement'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1700, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When considering winding distortion in power transformer, which sensor should be disregarded from the choices for monitoring this failure?\\nOptions:\\nA oil condition\\nB ultrasound\\nC frequency response analysis (fra)\\nD dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nE leak reactance flux\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When considering winding distortion in power transformer, which sensor should be disregarded from the choices for monitoring this failure?', 'options_text': ['oil condition', 'ultrasound', 'frequency response analysis (fra)', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'leak reactance flux'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 698, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, what is the key failure mode when vibration has abnormal readings?\\nOptions:\\nA damaged seals\\nB bearing wear\\nC cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, what is the key failure mode when vibration has abnormal readings?', 'options_text': ['damaged seals', 'bearing wear', 'cooling system fault'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor power?\n",
      "Options:\n",
      "A misalignment\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2034, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor compressor temperature?\\nOptions:\\nA compressor fouled\\nB compressor damaged\\nC unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor compressor temperature?', 'options_text': ['compressor fouled', 'compressor damaged', 'unbalance'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor among the choices best correlates with the presence of bearing damage in asset fan?\n",
      "Options:\n",
      "A pressure or vacuum\n",
      "B length measurement\n",
      "C air leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When considering winding distortion in power transformer, which sensor should be disregarded from the choices for monitoring this failure?\n",
      "Options:\n",
      "A frequency response analysis (fra)\n",
      "B ultrasound\n",
      "C leak reactance flux\n",
      "D dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the most relevant failure mode for compressor if vibration exhibits abnormal readings?\n",
      "Options:\n",
      "A damaged seals\n",
      "B cooling system fault\n",
      "C valve fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for industrial gas turbine if the sensor compressor temperature exhibits an abnormal reading?\n",
      "Options:\n",
      "A misalignment\n",
      "B compressor damaged\n",
      "C compressor fouled\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1701, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When considering winding distortion in power transformer, which sensor should be disregarded from the choices for monitoring this failure?\\nOptions:\\nA frequency response analysis (fra)\\nB ultrasound\\nC leak reactance flux\\nD dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When considering winding distortion in power transformer, which sensor should be disregarded from the choices for monitoring this failure?', 'options_text': ['frequency response analysis (fra)', 'ultrasound', 'leak reactance flux', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'temperature'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 699, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the most relevant failure mode for compressor if vibration exhibits abnormal readings?\\nOptions:\\nA damaged seals\\nB cooling system fault\\nC valve fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the most relevant failure mode for compressor if vibration exhibits abnormal readings?', 'options_text': ['damaged seals', 'cooling system fault', 'valve fault'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2035, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for industrial gas turbine if the sensor compressor temperature exhibits an abnormal reading?\\nOptions:\\nA misalignment\\nB compressor damaged\\nC compressor fouled\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for industrial gas turbine if the sensor compressor temperature exhibits an abnormal reading?', 'options_text': ['misalignment', 'compressor damaged', 'compressor fouled'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2369, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor power?\\nOptions:\\nA misalignment\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor power?', 'options_text': ['misalignment', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices does not indicate the presence of winding distortion in asset power transformer?\n",
      "Options:\n",
      "A ultrasound\n",
      "B leak reactance flux\n",
      "C partial discharge\n",
      "D dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "E frequency response analysis (fra)\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 365, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor among the choices best correlates with the presence of bearing damage in asset fan?\\nOptions:\\nA pressure or vacuum\\nB length measurement\\nC air leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor among the choices best correlates with the presence of bearing damage in asset fan?', 'options_text': ['pressure or vacuum', 'length measurement', 'air leakage'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When vibration in compressor displays abnormal readings, which failure mode is the most applicable?\n",
      "Options:\n",
      "A damaged seals\n",
      "B mounting fault\n",
      "C cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For industrial gas turbine, which failure event is not pertinent if the sensor compressor pressure registers an abnormal reading?\n",
      "Options:\n",
      "A combustion chamber holed\n",
      "B compressor damaged\n",
      "C fuel filter blockage\n",
      "D compressor fouled\n",
      "E air inlet blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In electric generator, which failure event is unimportant if the sensor torque shows an abnormal reading?\n",
      "Options:\n",
      "A rotor windings fault\n",
      "B brush(es) fault\n",
      "C bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices provides the strongest indication of bearing damage in fan?\n",
      "Options:\n",
      "A power\n",
      "B air leakage\n",
      "C pressure or vacuum\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 700, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When vibration in compressor displays abnormal readings, which failure mode is the most applicable?\\nOptions:\\nA damaged seals\\nB mounting fault\\nC cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When vibration in compressor displays abnormal readings, which failure mode is the most applicable?', 'options_text': ['damaged seals', 'mounting fault', 'cooling system fault'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1702, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices does not indicate the presence of winding distortion in asset power transformer?\\nOptions:\\nA ultrasound\\nB leak reactance flux\\nC partial discharge\\nD dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nE frequency response analysis (fra)\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices does not indicate the presence of winding distortion in asset power transformer?', 'options_text': ['ultrasound', 'leak reactance flux', 'partial discharge', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'frequency response analysis (fra)'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode should be considered for compressor when abnormal readings is detected by vibration?\n",
      "Options:\n",
      "A compressor stall\n",
      "B damaged seals\n",
      "C cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2370, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In electric generator, which failure event is unimportant if the sensor torque shows an abnormal reading?\\nOptions:\\nA rotor windings fault\\nB brush(es) fault\\nC bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In electric generator, which failure event is unimportant if the sensor torque shows an abnormal reading?', 'options_text': ['rotor windings fault', 'brush(es) fault', 'bearing damage'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if a failure event winding distortion occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A ultrasound\n",
      "B dissolved gas analysis\n",
      "C frequency response analysis (fra)\n",
      "D leak reactance flux\n",
      "E dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 366, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices provides the strongest indication of bearing damage in fan?\\nOptions:\\nA power\\nB air leakage\\nC pressure or vacuum\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices provides the strongest indication of bearing damage in fan?', 'options_text': ['power', 'air leakage', 'pressure or vacuum'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor torque?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B bearing damage\n",
      "C stator windings fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2036, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For industrial gas turbine, which failure event is not pertinent if the sensor compressor pressure registers an abnormal reading?\\nOptions:\\nA combustion chamber holed\\nB compressor damaged\\nC fuel filter blockage\\nD compressor fouled\\nE air inlet blockage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For industrial gas turbine, which failure event is not pertinent if the sensor compressor pressure registers an abnormal reading?', 'options_text': ['combustion chamber holed', 'compressor damaged', 'fuel filter blockage', 'compressor fouled', 'air inlet blockage'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a fan has bearing damage, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A air leakage\n",
      "B pressure or vacuum\n",
      "C speed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor compressor pressure?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B compressor damaged\n",
      "C burner blocked\n",
      "D air inlet blockage\n",
      "E fuel filter blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1703, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if a failure event winding distortion occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\\nOptions:\\nA ultrasound\\nB dissolved gas analysis\\nC frequency response analysis (fra)\\nD leak reactance flux\\nE dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if a failure event winding distortion occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?', 'options_text': ['ultrasound', 'dissolved gas analysis', 'frequency response analysis (fra)', 'leak reactance flux', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 367, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a fan has bearing damage, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA air leakage\\nB pressure or vacuum\\nC speed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a fan has bearing damage, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['air leakage', 'pressure or vacuum', 'speed'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2037, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor compressor pressure?\\nOptions:\\nA compressor fouled\\nB compressor damaged\\nC burner blocked\\nD air inlet blockage\\nE fuel filter blockage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor compressor pressure?', 'options_text': ['compressor fouled', 'compressor damaged', 'burner blocked', 'air inlet blockage', 'fuel filter blockage'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting winding distortion in power transformer?\n",
      "Options:\n",
      "A ultrasound\n",
      "B leak reactance flux\n",
      "C frequency response analysis (fra)\n",
      "D noise\n",
      "E dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2371, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor torque?\\nOptions:\\nA brush(es) fault\\nB bearing damage\\nC stator windings fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor torque?', 'options_text': ['brush(es) fault', 'bearing damage', 'stator windings fault'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For fan, if bearing damage happens, which sensor should be prioritized for monitoring this specific failure?\n",
      "Options:\n",
      "A air leakage\n",
      "B pressure or vacuum\n",
      "C vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor compressor pressure?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B fuel filter blockage\n",
      "C compressor damaged\n",
      "D power turbine damaged\n",
      "E air inlet blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 701, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode should be considered for compressor when abnormal readings is detected by vibration?\\nOptions:\\nA compressor stall\\nB damaged seals\\nC cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode should be considered for compressor when abnormal readings is detected by vibration?', 'options_text': ['compressor stall', 'damaged seals', 'cooling system fault'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor torque in electric generator shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B eccentric rotor\n",
      "C bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the most relevant failure mode for compressor if vibration exhibits abnormal readings?\n",
      "Options:\n",
      "A unbalance\n",
      "B cooling system fault\n",
      "C damaged seals\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 368, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For fan, if bearing damage happens, which sensor should be prioritized for monitoring this specific failure?\\nOptions:\\nA air leakage\\nB pressure or vacuum\\nC vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For fan, if bearing damage happens, which sensor should be prioritized for monitoring this specific failure?', 'options_text': ['air leakage', 'pressure or vacuum', 'vibration'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2372, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor torque in electric generator shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA brush(es) fault\\nB eccentric rotor\\nC bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor torque in electric generator shows an abnormal reading, which failure event is insignificant?', 'options_text': ['brush(es) fault', 'eccentric rotor', 'bearing damage'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 702, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the most relevant failure mode for compressor if vibration exhibits abnormal readings?\\nOptions:\\nA unbalance\\nB cooling system fault\\nC damaged seals\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the most relevant failure mode for compressor if vibration exhibits abnormal readings?', 'options_text': ['unbalance', 'cooling system fault', 'damaged seals'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1704, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor from the choices does not contribute significantly to detecting winding distortion in power transformer?\\nOptions:\\nA ultrasound\\nB leak reactance flux\\nC frequency response analysis (fra)\\nD noise\\nE dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor from the choices does not contribute significantly to detecting winding distortion in power transformer?', 'options_text': ['ultrasound', 'leak reactance flux', 'frequency response analysis (fra)', 'noise', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For fan, if bearing damage happens, which sensor should be prioritized for monitoring this specific failure?\n",
      "Options:\n",
      "A temperature\n",
      "B pressure or vacuum\n",
      "C air leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2038, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor compressor pressure?\\nOptions:\\nA compressor fouled\\nB fuel filter blockage\\nC compressor damaged\\nD power turbine damaged\\nE air inlet blockage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor compressor pressure?', 'options_text': ['compressor fouled', 'fuel filter blockage', 'compressor damaged', 'power turbine damaged', 'air inlet blockage'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In electric generator, which failure event is unimportant if the sensor torque shows an abnormal reading?\n",
      "Options:\n",
      "A bearing damage\n",
      "B insulation deterioration\n",
      "C brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, which failure mode is pertinent if vibration registers abnormal readings?\n",
      "Options:\n",
      "A misalignment\n",
      "B damaged seals\n",
      "C cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting winding distortion in power transformer?\n",
      "Options:\n",
      "A dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "B ultrasound\n",
      "C frequency response analysis (fra)\n",
      "D vibration\n",
      "E leak reactance flux\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor compressor pressure in industrial gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A bearing wear\n",
      "B compressor damaged\n",
      "C air inlet blockage\n",
      "D fuel filter blockage\n",
      "E compressor fouled\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2039, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor compressor pressure in industrial gas turbine, which failure event is not relevant?\\nOptions:\\nA bearing wear\\nB compressor damaged\\nC air inlet blockage\\nD fuel filter blockage\\nE compressor fouled\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor compressor pressure in industrial gas turbine, which failure event is not relevant?', 'options_text': ['bearing wear', 'compressor damaged', 'air inlet blockage', 'fuel filter blockage', 'compressor fouled'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 369, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For fan, if bearing damage happens, which sensor should be prioritized for monitoring this specific failure?\\nOptions:\\nA temperature\\nB pressure or vacuum\\nC air leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For fan, if bearing damage happens, which sensor should be prioritized for monitoring this specific failure?', 'options_text': ['temperature', 'pressure or vacuum', 'air leakage'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In industrial gas turbine, which failure event is unimportant if the sensor compressor pressure shows an abnormal reading?\n",
      "Options:\n",
      "A fuel filter blockage\n",
      "B unbalance\n",
      "C compressor damaged\n",
      "D air inlet blockage\n",
      "E compressor fouled\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1705, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor from the choices does not contribute significantly to detecting winding distortion in power transformer?\\nOptions:\\nA dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nB ultrasound\\nC frequency response analysis (fra)\\nD vibration\\nE leak reactance flux\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor from the choices does not contribute significantly to detecting winding distortion in power transformer?', 'options_text': ['dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'ultrasound', 'frequency response analysis (fra)', 'vibration', 'leak reactance flux'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a fan has bearing damage, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A pressure or vacuum\n",
      "B coast down time\n",
      "C air leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 703, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, which failure mode is pertinent if vibration registers abnormal readings?\\nOptions:\\nA misalignment\\nB damaged seals\\nC cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, which failure mode is pertinent if vibration registers abnormal readings?', 'options_text': ['misalignment', 'damaged seals', 'cooling system fault'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2373, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In electric generator, which failure event is unimportant if the sensor torque shows an abnormal reading?\\nOptions:\\nA bearing damage\\nB insulation deterioration\\nC brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In electric generator, which failure event is unimportant if the sensor torque shows an abnormal reading?', 'options_text': ['bearing damage', 'insulation deterioration', 'brush(es) fault'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices does not indicate the presence of winding distortion in asset power transformer?\n",
      "Options:\n",
      "A frequency response analysis (fra)\n",
      "B power factor/tanδ\n",
      "C dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "D leak reactance flux\n",
      "E ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the most relevant failure mode for compressor if temperature exhibits abnormal readings?\n",
      "Options:\n",
      "A misalignment\n",
      "B damaged seals\n",
      "C unbalance\n",
      "D mounting fault\n",
      "E damaged impeller\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor torque in electric generator shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A bearing damage\n",
      "B brush(es) fault\n",
      "C loss of output power phase\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2374, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor torque in electric generator shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA bearing damage\\nB brush(es) fault\\nC loss of output power phase\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor torque in electric generator shows an abnormal reading, which failure event is insignificant?', 'options_text': ['bearing damage', 'brush(es) fault', 'loss of output power phase'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2040, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In industrial gas turbine, which failure event is unimportant if the sensor compressor pressure shows an abnormal reading?\\nOptions:\\nA fuel filter blockage\\nB unbalance\\nC compressor damaged\\nD air inlet blockage\\nE compressor fouled\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In industrial gas turbine, which failure event is unimportant if the sensor compressor pressure shows an abnormal reading?', 'options_text': ['fuel filter blockage', 'unbalance', 'compressor damaged', 'air inlet blockage', 'compressor fouled'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event is irrelevant for electric generator if there is an abnormal reading from the sensor torque?\n",
      "Options:\n",
      "A unbalance\n",
      "B brush(es) fault\n",
      "C bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for industrial gas turbine if the sensor compressor pressure exhibits an abnormal reading?\n",
      "Options:\n",
      "A compressor damaged\n",
      "B fuel filter blockage\n",
      "C air inlet blockage\n",
      "D compressor fouled\n",
      "E misalignment\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 704, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the most relevant failure mode for compressor if temperature exhibits abnormal readings?\\nOptions:\\nA misalignment\\nB damaged seals\\nC unbalance\\nD mounting fault\\nE damaged impeller\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the most relevant failure mode for compressor if temperature exhibits abnormal readings?', 'options_text': ['misalignment', 'damaged seals', 'unbalance', 'mounting fault', 'damaged impeller'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 370, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a fan has bearing damage, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA pressure or vacuum\\nB coast down time\\nC air leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a fan has bearing damage, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['pressure or vacuum', 'coast down time', 'air leakage'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1706, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices does not indicate the presence of winding distortion in asset power transformer?\\nOptions:\\nA frequency response analysis (fra)\\nB power factor/tanδ\\nC dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nD leak reactance flux\\nE ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices does not indicate the presence of winding distortion in asset power transformer?', 'options_text': ['frequency response analysis (fra)', 'power factor/tanδ', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'leak reactance flux', 'ultrasound'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, which failure mode is pertinent if temperature registers abnormal readings?\n",
      "Options:\n",
      "A misalignment\n",
      "B unbalance\n",
      "C mounting fault\n",
      "D eccentric impeller\n",
      "E damaged seals\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For fan, if bearing damage happens, which sensor should be prioritized for monitoring this specific failure?\n",
      "Options:\n",
      "A air leakage\n",
      "B pressure or vacuum\n",
      "C oil debris\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When considering winding distortion in power transformer, which sensor should be disregarded from the choices for monitoring this failure?\n",
      "Options:\n",
      "A leak reactance flux\n",
      "B dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "C resistance\n",
      "D ultrasound\n",
      "E frequency response analysis (fra)\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 371, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For fan, if bearing damage happens, which sensor should be prioritized for monitoring this specific failure?\\nOptions:\\nA air leakage\\nB pressure or vacuum\\nC oil debris\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For fan, if bearing damage happens, which sensor should be prioritized for monitoring this specific failure?', 'options_text': ['air leakage', 'pressure or vacuum', 'oil debris'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1707, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When considering winding distortion in power transformer, which sensor should be disregarded from the choices for monitoring this failure?\\nOptions:\\nA leak reactance flux\\nB dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nC resistance\\nD ultrasound\\nE frequency response analysis (fra)\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When considering winding distortion in power transformer, which sensor should be disregarded from the choices for monitoring this failure?', 'options_text': ['leak reactance flux', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'resistance', 'ultrasound', 'frequency response analysis (fra)'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 705, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, which failure mode is pertinent if temperature registers abnormal readings?\\nOptions:\\nA misalignment\\nB unbalance\\nC mounting fault\\nD eccentric impeller\\nE damaged seals\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, which failure mode is pertinent if temperature registers abnormal readings?', 'options_text': ['misalignment', 'unbalance', 'mounting fault', 'eccentric impeller', 'damaged seals'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2041, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for industrial gas turbine if the sensor compressor pressure exhibits an abnormal reading?\\nOptions:\\nA compressor damaged\\nB fuel filter blockage\\nC air inlet blockage\\nD compressor fouled\\nE misalignment\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for industrial gas turbine if the sensor compressor pressure exhibits an abnormal reading?', 'options_text': ['compressor damaged', 'fuel filter blockage', 'air inlet blockage', 'compressor fouled', 'misalignment'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with bearing damage in fan, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A pressure or vacuum\n",
      "B air leakage\n",
      "C oil leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2375, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event is irrelevant for electric generator if there is an abnormal reading from the sensor torque?\\nOptions:\\nA unbalance\\nB brush(es) fault\\nC bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event is irrelevant for electric generator if there is an abnormal reading from the sensor torque?', 'options_text': ['unbalance', 'brush(es) fault', 'bearing damage'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of winding distortion in power transformer?\n",
      "Options:\n",
      "A frequency response analysis (fra)\n",
      "B ultrasound\n",
      "C excitation current\n",
      "D dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "E leak reactance flux\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When temperature detects abnormal readings in compressor, which failure mode is the most relevant?\n",
      "Options:\n",
      "A mounting fault\n",
      "B misalignment\n",
      "C unbalance\n",
      "D bearing damage\n",
      "E damaged seals\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor air flow?\n",
      "Options:\n",
      "A compressor damaged\n",
      "B compressor fouled\n",
      "C air inlet blockage\n",
      "D fuel filter blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor torque in electric generator, which failure event is not relevant?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B misalignment\n",
      "C bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 372, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with bearing damage in fan, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA pressure or vacuum\\nB air leakage\\nC oil leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with bearing damage in fan, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['pressure or vacuum', 'air leakage', 'oil leakage'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices provides the strongest indication of bearing wear in fan?\n",
      "Options:\n",
      "A pressure or vacuum\n",
      "B power\n",
      "C length measurement\n",
      "D speed\n",
      "E oil leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 706, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When temperature detects abnormal readings in compressor, which failure mode is the most relevant?\\nOptions:\\nA mounting fault\\nB misalignment\\nC unbalance\\nD bearing damage\\nE damaged seals\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When temperature detects abnormal readings in compressor, which failure mode is the most relevant?', 'options_text': ['mounting fault', 'misalignment', 'unbalance', 'bearing damage', 'damaged seals'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2042, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor air flow?\\nOptions:\\nA compressor damaged\\nB compressor fouled\\nC air inlet blockage\\nD fuel filter blockage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor air flow?', 'options_text': ['compressor damaged', 'compressor fouled', 'air inlet blockage', 'fuel filter blockage'], 'true_answer': [False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1708, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of winding distortion in power transformer?\\nOptions:\\nA frequency response analysis (fra)\\nB ultrasound\\nC excitation current\\nD dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nE leak reactance flux\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of winding distortion in power transformer?', 'options_text': ['frequency response analysis (fra)', 'ultrasound', 'excitation current', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'leak reactance flux'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2376, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor torque in electric generator, which failure event is not relevant?\\nOptions:\\nA brush(es) fault\\nB misalignment\\nC bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor torque in electric generator, which failure event is not relevant?', 'options_text': ['brush(es) fault', 'misalignment', 'bearing damage'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the most relevant failure mode for compressor if temperature exhibits abnormal readings?\n",
      "Options:\n",
      "A bearing wear\n",
      "B unbalance\n",
      "C damaged seals\n",
      "D compressor stall\n",
      "E misalignment\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor air flow?\n",
      "Options:\n",
      "A air inlet blockage\n",
      "B combustion chamber holed\n",
      "C compressor fouled\n",
      "D compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if a failure event winding distortion occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A leak reactance flux\n",
      "B ultrasound\n",
      "C frequency response analysis (fra)\n",
      "D dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "E bushing capacitance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor radio frequency emissions in electric generator, which failure event is not relevant?\n",
      "Options:\n",
      "A rotor windings fault\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2377, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor radio frequency emissions in electric generator, which failure event is not relevant?\\nOptions:\\nA rotor windings fault\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor radio frequency emissions in electric generator, which failure event is not relevant?', 'options_text': ['rotor windings fault', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1709, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if a failure event winding distortion occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\\nOptions:\\nA leak reactance flux\\nB ultrasound\\nC frequency response analysis (fra)\\nD dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nE bushing capacitance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if a failure event winding distortion occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?', 'options_text': ['leak reactance flux', 'ultrasound', 'frequency response analysis (fra)', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'bushing capacitance'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 707, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the most relevant failure mode for compressor if temperature exhibits abnormal readings?\\nOptions:\\nA bearing wear\\nB unbalance\\nC damaged seals\\nD compressor stall\\nE misalignment\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the most relevant failure mode for compressor if temperature exhibits abnormal readings?', 'options_text': ['bearing wear', 'unbalance', 'damaged seals', 'compressor stall', 'misalignment'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2043, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor air flow?\\nOptions:\\nA air inlet blockage\\nB combustion chamber holed\\nC compressor fouled\\nD compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor air flow?', 'options_text': ['air inlet blockage', 'combustion chamber holed', 'compressor fouled', 'compressor damaged'], 'true_answer': [False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 40 / 329 samples completed.\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 373, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices provides the strongest indication of bearing wear in fan?\\nOptions:\\nA pressure or vacuum\\nB power\\nC length measurement\\nD speed\\nE oil leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices provides the strongest indication of bearing wear in fan?', 'options_text': ['pressure or vacuum', 'power', 'length measurement', 'speed', 'oil leakage'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 40 / 334 samples completed.\n",
      "INFO:root:One thread 40 / 334 samples completed.\n",
      "INFO:root:One thread 40 / 334 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event is irrelevant for electric generator if there is an abnormal reading from the sensor radio frequency emissions?\n",
      "Options:\n",
      "A stator windings fault\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:One thread 40 / 334 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a power transformer has winding looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A vibration\n",
      "B noise\n",
      "C amps/ volts/ load\n",
      "D ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, what is the key failure mode when temperature has abnormal readings?\n",
      "Options:\n",
      "A unbalance\n",
      "B mounting fault\n",
      "C damaged seals\n",
      "D cooling system fault\n",
      "E compressor stall\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor air flow in industrial gas turbine shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B burner blocked\n",
      "C air inlet blockage\n",
      "D compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with bearing wear in fan, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A vibration\n",
      "B air leakage\n",
      "C oil leakage\n",
      "D power\n",
      "E pressure or vacuum\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1710, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a power transformer has winding looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA vibration\\nB noise\\nC amps/ volts/ load\\nD ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a power transformer has winding looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['vibration', 'noise', 'amps/ volts/ load', 'ultrasound'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 708, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, what is the key failure mode when temperature has abnormal readings?\\nOptions:\\nA unbalance\\nB mounting fault\\nC damaged seals\\nD cooling system fault\\nE compressor stall\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, what is the key failure mode when temperature has abnormal readings?', 'options_text': ['unbalance', 'mounting fault', 'damaged seals', 'cooling system fault', 'compressor stall'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2378, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event is irrelevant for electric generator if there is an abnormal reading from the sensor radio frequency emissions?\\nOptions:\\nA stator windings fault\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event is irrelevant for electric generator if there is an abnormal reading from the sensor radio frequency emissions?', 'options_text': ['stator windings fault', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if a failure event winding looseness occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A vibration\n",
      "B ultrasound\n",
      "C visual\n",
      "D noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 374, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with bearing wear in fan, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA vibration\\nB air leakage\\nC oil leakage\\nD power\\nE pressure or vacuum\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with bearing wear in fan, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['vibration', 'air leakage', 'oil leakage', 'power', 'pressure or vacuum'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In compressor, which failure mode is most important if temperature shows abnormal readings?\n",
      "Options:\n",
      "A damaged seals\n",
      "B misalignment\n",
      "C compressor stall\n",
      "D valve fault\n",
      "E unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor radio frequency emissions in electric generator shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B eccentric rotor\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2044, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor air flow in industrial gas turbine shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA compressor fouled\\nB burner blocked\\nC air inlet blockage\\nD compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor air flow in industrial gas turbine shows an abnormal reading, which failure event is insignificant?', 'options_text': ['compressor fouled', 'burner blocked', 'air inlet blockage', 'compressor damaged'], 'true_answer': [False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For fan, if bearing wear happens, which sensor should be prioritized for monitoring this specific failure?\n",
      "Options:\n",
      "A speed\n",
      "B power\n",
      "C pressure or vacuum\n",
      "D oil leakage\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In industrial gas turbine, which failure event is unimportant if the sensor air flow shows an abnormal reading?\n",
      "Options:\n",
      "A compressor damaged\n",
      "B compressor fouled\n",
      "C power turbine damaged\n",
      "D air inlet blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 375, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For fan, if bearing wear happens, which sensor should be prioritized for monitoring this specific failure?\\nOptions:\\nA speed\\nB power\\nC pressure or vacuum\\nD oil leakage\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For fan, if bearing wear happens, which sensor should be prioritized for monitoring this specific failure?', 'options_text': ['speed', 'power', 'pressure or vacuum', 'oil leakage', 'temperature'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 709, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In compressor, which failure mode is most important if temperature shows abnormal readings?\\nOptions:\\nA damaged seals\\nB misalignment\\nC compressor stall\\nD valve fault\\nE unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In compressor, which failure mode is most important if temperature shows abnormal readings?', 'options_text': ['damaged seals', 'misalignment', 'compressor stall', 'valve fault', 'unbalance'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1711, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if a failure event winding looseness occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\\nOptions:\\nA vibration\\nB ultrasound\\nC visual\\nD noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if a failure event winding looseness occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?', 'options_text': ['vibration', 'ultrasound', 'visual', 'noise'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2045, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In industrial gas turbine, which failure event is unimportant if the sensor air flow shows an abnormal reading?\\nOptions:\\nA compressor damaged\\nB compressor fouled\\nC power turbine damaged\\nD air inlet blockage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In industrial gas turbine, which failure event is unimportant if the sensor air flow shows an abnormal reading?', 'options_text': ['compressor damaged', 'compressor fouled', 'power turbine damaged', 'air inlet blockage'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For fan, if bearing wear happens, which sensor should be prioritized for monitoring this specific failure?\n",
      "Options:\n",
      "A air leakage\n",
      "B pressure or vacuum\n",
      "C oil leakage\n",
      "D coast down time\n",
      "E speed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2379, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor radio frequency emissions in electric generator shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA brush(es) fault\\nB eccentric rotor\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor radio frequency emissions in electric generator shows an abnormal reading, which failure event is insignificant?', 'options_text': ['brush(es) fault', 'eccentric rotor'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode should be considered for compressor when abnormal readings is detected by coast down time?\n",
      "Options:\n",
      "A cooling system fault\n",
      "B compressor stall\n",
      "C damaged impeller\n",
      "D valve fault\n",
      "E unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?\n",
      "Options:\n",
      "A oil condition\n",
      "B ultrasound\n",
      "C noise\n",
      "D vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For industrial gas turbine, which failure event is not pertinent if the sensor air flow registers an abnormal reading?\n",
      "Options:\n",
      "A bearing wear\n",
      "B compressor damaged\n",
      "C air inlet blockage\n",
      "D compressor fouled\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, what is the non-relevant failure event when the sensor radio frequency emissions has an abnormal reading?\n",
      "Options:\n",
      "A bearing damage\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 710, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode should be considered for compressor when abnormal readings is detected by coast down time?\\nOptions:\\nA cooling system fault\\nB compressor stall\\nC damaged impeller\\nD valve fault\\nE unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode should be considered for compressor when abnormal readings is detected by coast down time?', 'options_text': ['cooling system fault', 'compressor stall', 'damaged impeller', 'valve fault', 'unbalance'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode is most relevant for compressor if there are abnormal readings from coast down time?\n",
      "Options:\n",
      "A misalignment\n",
      "B valve fault\n",
      "C compressor stall\n",
      "D eccentric impeller\n",
      "E mounting fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2046, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For industrial gas turbine, which failure event is not pertinent if the sensor air flow registers an abnormal reading?\\nOptions:\\nA bearing wear\\nB compressor damaged\\nC air inlet blockage\\nD compressor fouled\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For industrial gas turbine, which failure event is not pertinent if the sensor air flow registers an abnormal reading?', 'options_text': ['bearing wear', 'compressor damaged', 'air inlet blockage', 'compressor fouled'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2380, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, what is the non-relevant failure event when the sensor radio frequency emissions has an abnormal reading?\\nOptions:\\nA bearing damage\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, what is the non-relevant failure event when the sensor radio frequency emissions has an abnormal reading?', 'options_text': ['bearing damage', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1712, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?\\nOptions:\\nA oil condition\\nB ultrasound\\nC noise\\nD vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?', 'options_text': ['oil condition', 'ultrasound', 'noise', 'vibration'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 376, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For fan, if bearing wear happens, which sensor should be prioritized for monitoring this specific failure?\\nOptions:\\nA air leakage\\nB pressure or vacuum\\nC oil leakage\\nD coast down time\\nE speed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For fan, if bearing wear happens, which sensor should be prioritized for monitoring this specific failure?', 'options_text': ['air leakage', 'pressure or vacuum', 'oil leakage', 'coast down time', 'speed'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor air flow?\n",
      "Options:\n",
      "A compressor damaged\n",
      "B compressor fouled\n",
      "C air inlet blockage\n",
      "D unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of electric generator, which failure event is not relevant when the sensor radio frequency emissions shows an abnormal reading?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B insulation deterioration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?\n",
      "Options:\n",
      "A vibration\n",
      "B noise\n",
      "C temperature\n",
      "D ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices provides the strongest indication of bearing wear in fan?\n",
      "Options:\n",
      "A power\n",
      "B air leakage\n",
      "C speed\n",
      "D oil debris\n",
      "E oil leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2047, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor air flow?\\nOptions:\\nA compressor damaged\\nB compressor fouled\\nC air inlet blockage\\nD unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor air flow?', 'options_text': ['compressor damaged', 'compressor fouled', 'air inlet blockage', 'unbalance'], 'true_answer': [False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1713, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?\\nOptions:\\nA vibration\\nB noise\\nC temperature\\nD ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?', 'options_text': ['vibration', 'noise', 'temperature', 'ultrasound'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 711, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode is most relevant for compressor if there are abnormal readings from coast down time?\\nOptions:\\nA misalignment\\nB valve fault\\nC compressor stall\\nD eccentric impeller\\nE mounting fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode is most relevant for compressor if there are abnormal readings from coast down time?', 'options_text': ['misalignment', 'valve fault', 'compressor stall', 'eccentric impeller', 'mounting fault'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2381, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of electric generator, which failure event is not relevant when the sensor radio frequency emissions shows an abnormal reading?\\nOptions:\\nA brush(es) fault\\nB insulation deterioration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of electric generator, which failure event is not relevant when the sensor radio frequency emissions shows an abnormal reading?', 'options_text': ['brush(es) fault', 'insulation deterioration'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor air flow in industrial gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A air inlet blockage\n",
      "B compressor damaged\n",
      "C misalignment\n",
      "D compressor fouled\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 377, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices provides the strongest indication of bearing wear in fan?\\nOptions:\\nA power\\nB air leakage\\nC speed\\nD oil debris\\nE oil leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices provides the strongest indication of bearing wear in fan?', 'options_text': ['power', 'air leakage', 'speed', 'oil debris', 'oil leakage'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if winding looseness occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\n",
      "Options:\n",
      "A vibration\n",
      "B partial discharge\n",
      "C ultrasound\n",
      "D noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When coast down time detects abnormal readings in compressor, which failure mode is the most relevant?\n",
      "Options:\n",
      "A compressor stall\n",
      "B unbalance\n",
      "C valve fault\n",
      "D mounting fault\n",
      "E bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor radio frequency emissions in electric generator displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A loss of output power phase\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with mounting fault in fan, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A oil debris\n",
      "B vibration\n",
      "C length measurement\n",
      "D power\n",
      "E speed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1714, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if winding looseness occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\\nOptions:\\nA vibration\\nB partial discharge\\nC ultrasound\\nD noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if winding looseness occurs, which sensor among the choices is least likely to be relevant in identifying this failure?', 'options_text': ['vibration', 'partial discharge', 'ultrasound', 'noise'], 'true_answer': [False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2048, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor air flow in industrial gas turbine, which failure event is not relevant?\\nOptions:\\nA air inlet blockage\\nB compressor damaged\\nC misalignment\\nD compressor fouled\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor air flow in industrial gas turbine, which failure event is not relevant?', 'options_text': ['air inlet blockage', 'compressor damaged', 'misalignment', 'compressor fouled'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices does not indicate the presence of winding looseness in asset power transformer?\n",
      "Options:\n",
      "A vibration\n",
      "B noise\n",
      "C dissolved gas analysis\n",
      "D ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 712, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When coast down time detects abnormal readings in compressor, which failure mode is the most relevant?\\nOptions:\\nA compressor stall\\nB unbalance\\nC valve fault\\nD mounting fault\\nE bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When coast down time detects abnormal readings in compressor, which failure mode is the most relevant?', 'options_text': ['compressor stall', 'unbalance', 'valve fault', 'mounting fault', 'bearing damage'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor fuel pressure/ fuel flow?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B burner blocked\n",
      "C fuel filter blockage\n",
      "D air inlet blockage\n",
      "E combustion chamber holed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2382, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor radio frequency emissions in electric generator displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA loss of output power phase\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor radio frequency emissions in electric generator displays an abnormal reading, which failure event is not applicable?', 'options_text': ['loss of output power phase', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 378, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with mounting fault in fan, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA oil debris\\nB vibration\\nC length measurement\\nD power\\nE speed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with mounting fault in fan, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['oil debris', 'vibration', 'length measurement', 'power', 'speed'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For compressor, which failure mode is pertinent if coast down time registers abnormal readings?\n",
      "Options:\n",
      "A mounting fault\n",
      "B misalignment\n",
      "C cooling system fault\n",
      "D bearing wear\n",
      "E damaged seals\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In electric generator, which failure event is unimportant if the sensor radio frequency emissions shows an abnormal reading?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For fan, if a failure event rotor fouled occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A vibration\n",
      "B air leakage\n",
      "C oil debris\n",
      "D pressure or vacuum\n",
      "E oil leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1715, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices does not indicate the presence of winding looseness in asset power transformer?\\nOptions:\\nA vibration\\nB noise\\nC dissolved gas analysis\\nD ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices does not indicate the presence of winding looseness in asset power transformer?', 'options_text': ['vibration', 'noise', 'dissolved gas analysis', 'ultrasound'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2383, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In electric generator, which failure event is unimportant if the sensor radio frequency emissions shows an abnormal reading?\\nOptions:\\nA brush(es) fault\\nB unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In electric generator, which failure event is unimportant if the sensor radio frequency emissions shows an abnormal reading?', 'options_text': ['brush(es) fault', 'unbalance'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2049, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor fuel pressure/ fuel flow?\\nOptions:\\nA compressor fouled\\nB burner blocked\\nC fuel filter blockage\\nD air inlet blockage\\nE combustion chamber holed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor fuel pressure/ fuel flow?', 'options_text': ['compressor fouled', 'burner blocked', 'fuel filter blockage', 'air inlet blockage', 'combustion chamber holed'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if a failure event winding looseness occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A vibration\n",
      "B ultrasound\n",
      "C power factor/tanδ\n",
      "D noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 379, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For fan, if a failure event rotor fouled occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\\nOptions:\\nA vibration\\nB air leakage\\nC oil debris\\nD pressure or vacuum\\nE oil leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For fan, if a failure event rotor fouled occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?', 'options_text': ['vibration', 'air leakage', 'oil debris', 'pressure or vacuum', 'oil leakage'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 713, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For compressor, which failure mode is pertinent if coast down time registers abnormal readings?\\nOptions:\\nA mounting fault\\nB misalignment\\nC cooling system fault\\nD bearing wear\\nE damaged seals\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For compressor, which failure mode is pertinent if coast down time registers abnormal readings?', 'options_text': ['mounting fault', 'misalignment', 'cooling system fault', 'bearing wear', 'damaged seals'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor radio frequency emissions in electric generator displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A misalignment\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor fuel pressure/ fuel flow in industrial gas turbine displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A power turbine damaged\n",
      "B burner blocked\n",
      "C compressor damaged\n",
      "D fuel filter blockage\n",
      "E combustion chamber holed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For fan, if unbalance happens, which sensor should be prioritized for monitoring this specific failure?\n",
      "Options:\n",
      "A vibration\n",
      "B air leakage\n",
      "C oil debris\n",
      "D coast down time\n",
      "E pressure or vacuum\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode should be considered for compressor when abnormal readings is detected by oil debris?\n",
      "Options:\n",
      "A compressor stall\n",
      "B valve fault\n",
      "C eccentric impeller\n",
      "D damaged impeller\n",
      "E misalignment\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "46\n",
      "46\n",
      "46\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1716, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if a failure event winding looseness occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\\nOptions:\\nA vibration\\nB ultrasound\\nC power factor/tanδ\\nD noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if a failure event winding looseness occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?', 'options_text': ['vibration', 'ultrasound', 'power factor/tanδ', 'noise'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2050, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor fuel pressure/ fuel flow in industrial gas turbine displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA power turbine damaged\\nB burner blocked\\nC compressor damaged\\nD fuel filter blockage\\nE combustion chamber holed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor fuel pressure/ fuel flow in industrial gas turbine displays an abnormal reading, which failure event is not applicable?', 'options_text': ['power turbine damaged', 'burner blocked', 'compressor damaged', 'fuel filter blockage', 'combustion chamber holed'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?\n",
      "Options:\n",
      "A noise\n",
      "B resistance\n",
      "C ultrasound\n",
      "D vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 380, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For fan, if unbalance happens, which sensor should be prioritized for monitoring this specific failure?\\nOptions:\\nA vibration\\nB air leakage\\nC oil debris\\nD coast down time\\nE pressure or vacuum\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For fan, if unbalance happens, which sensor should be prioritized for monitoring this specific failure?', 'options_text': ['vibration', 'air leakage', 'oil debris', 'coast down time', 'pressure or vacuum'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For industrial gas turbine, which failure event is not pertinent if the sensor fuel pressure/ fuel flow registers an abnormal reading?\n",
      "Options:\n",
      "A compressor damaged\n",
      "B burner blocked\n",
      "C combustion chamber holed\n",
      "D fuel filter blockage\n",
      "E bearing wear\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2384, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor radio frequency emissions in electric generator displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA misalignment\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor radio frequency emissions in electric generator displays an abnormal reading, which failure event is not applicable?', 'options_text': ['misalignment', 'brush(es) fault'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 714, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode should be considered for compressor when abnormal readings is detected by oil debris?\\nOptions:\\nA compressor stall\\nB valve fault\\nC eccentric impeller\\nD damaged impeller\\nE misalignment\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode should be considered for compressor when abnormal readings is detected by oil debris?', 'options_text': ['compressor stall', 'valve fault', 'eccentric impeller', 'damaged impeller', 'misalignment'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with misalignment in fan, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A coast down time\n",
      "B oil debris\n",
      "C power\n",
      "D length measurement\n",
      "E pressure or vacuum\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor vibration in electric generator displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A unbalance\n",
      "B bearing damage\n",
      "C brush(es) fault\n",
      "D rotor windings fault\n",
      "E misalignment\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In compressor, which failure mode is most important if oil debris shows abnormal readings?\n",
      "Options:\n",
      "A unbalance\n",
      "B damaged seals\n",
      "C mounting fault\n",
      "D compressor stall\n",
      "E eccentric impeller\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "47\n",
      "47\n",
      "47\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2385, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor vibration in electric generator displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA unbalance\\nB bearing damage\\nC brush(es) fault\\nD rotor windings fault\\nE misalignment\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor vibration in electric generator displays an abnormal reading, which failure event is not applicable?', 'options_text': ['unbalance', 'bearing damage', 'brush(es) fault', 'rotor windings fault', 'misalignment'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, which failure event is not pertinent if the sensor vibration registers an abnormal reading?\n",
      "Options:\n",
      "A misalignment\n",
      "B bearing damage\n",
      "C insulation deterioration\n",
      "D loss of output power phase\n",
      "E eccentric rotor\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1717, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?\\nOptions:\\nA noise\\nB resistance\\nC ultrasound\\nD vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?', 'options_text': ['noise', 'resistance', 'ultrasound', 'vibration'], 'true_answer': [False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 381, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with misalignment in fan, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA coast down time\\nB oil debris\\nC power\\nD length measurement\\nE pressure or vacuum\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with misalignment in fan, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['coast down time', 'oil debris', 'power', 'length measurement', 'pressure or vacuum'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 715, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In compressor, which failure mode is most important if oil debris shows abnormal readings?\\nOptions:\\nA unbalance\\nB damaged seals\\nC mounting fault\\nD compressor stall\\nE eccentric impeller\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In compressor, which failure mode is most important if oil debris shows abnormal readings?', 'options_text': ['unbalance', 'damaged seals', 'mounting fault', 'compressor stall', 'eccentric impeller'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if winding looseness occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\n",
      "Options:\n",
      "A dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "B ultrasound\n",
      "C vibration\n",
      "D noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In fan, when misalignment occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\n",
      "Options:\n",
      "A pressure or vacuum\n",
      "B vibration\n",
      "C coast down time\n",
      "D oil debris\n",
      "E air leakage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2051, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For industrial gas turbine, which failure event is not pertinent if the sensor fuel pressure/ fuel flow registers an abnormal reading?\\nOptions:\\nA compressor damaged\\nB burner blocked\\nC combustion chamber holed\\nD fuel filter blockage\\nE bearing wear\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For industrial gas turbine, which failure event is not pertinent if the sensor fuel pressure/ fuel flow registers an abnormal reading?', 'options_text': ['compressor damaged', 'burner blocked', 'combustion chamber holed', 'fuel filter blockage', 'bearing wear'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the most relevant failure mode for compressor if oil debris exhibits abnormal readings?\n",
      "Options:\n",
      "A unbalance\n",
      "B bearing damage\n",
      "C eccentric impeller\n",
      "D mounting fault\n",
      "E compressor stall\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor fuel pressure/ fuel flow in industrial gas turbine displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B compressor damaged\n",
      "C unbalance\n",
      "D burner blocked\n",
      "E combustion chamber holed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 716, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the most relevant failure mode for compressor if oil debris exhibits abnormal readings?\\nOptions:\\nA unbalance\\nB bearing damage\\nC eccentric impeller\\nD mounting fault\\nE compressor stall\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the most relevant failure mode for compressor if oil debris exhibits abnormal readings?', 'options_text': ['unbalance', 'bearing damage', 'eccentric impeller', 'mounting fault', 'compressor stall'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1718, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if winding looseness occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\\nOptions:\\nA dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nB ultrasound\\nC vibration\\nD noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if winding looseness occurs, which sensor among the choices is least likely to be relevant in identifying this failure?', 'options_text': ['dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'ultrasound', 'vibration', 'noise'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 382, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In fan, when misalignment occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\\nOptions:\\nA pressure or vacuum\\nB vibration\\nC coast down time\\nD oil debris\\nE air leakage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In fan, when misalignment occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?', 'options_text': ['pressure or vacuum', 'vibration', 'coast down time', 'oil debris', 'air leakage'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2052, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor fuel pressure/ fuel flow in industrial gas turbine displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA compressor fouled\\nB compressor damaged\\nC unbalance\\nD burner blocked\\nE combustion chamber holed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor fuel pressure/ fuel flow in industrial gas turbine displays an abnormal reading, which failure event is not applicable?', 'options_text': ['compressor fouled', 'compressor damaged', 'unbalance', 'burner blocked', 'combustion chamber holed'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode is most relevant for compressor if there are abnormal readings from oil debris?\n",
      "Options:\n",
      "A bearing wear\n",
      "B valve fault\n",
      "C compressor stall\n",
      "D unbalance\n",
      "E eccentric impeller\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2386, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, which failure event is not pertinent if the sensor vibration registers an abnormal reading?\\nOptions:\\nA misalignment\\nB bearing damage\\nC insulation deterioration\\nD loss of output power phase\\nE eccentric rotor\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, which failure event is not pertinent if the sensor vibration registers an abnormal reading?', 'options_text': ['misalignment', 'bearing damage', 'insulation deterioration', 'loss of output power phase', 'eccentric rotor'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?\n",
      "Options:\n",
      "A noise\n",
      "B frequency response analysis (fra)\n",
      "C vibration\n",
      "D ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices can indicate the presence of insulation deterioration in asset power transformer?\n",
      "Options:\n",
      "A bushing capacitance\n",
      "B vibration\n",
      "C amps/ volts/ load\n",
      "D noise\n",
      "E visual\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor fuel pressure/ fuel flow in industrial gas turbine displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B burner blocked\n",
      "C fuel filter blockage\n",
      "D misalignment\n",
      "E compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of electric generator, which failure event is not relevant when the sensor temparature shows an abnormal reading?\n",
      "Options:\n",
      "A stator windings fault\n",
      "B bearing damage\n",
      "C brush(es) fault\n",
      "D eccentric rotor\n",
      "E rotor windings fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 717, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode is most relevant for compressor if there are abnormal readings from oil debris?\\nOptions:\\nA bearing wear\\nB valve fault\\nC compressor stall\\nD unbalance\\nE eccentric impeller\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode is most relevant for compressor if there are abnormal readings from oil debris?', 'options_text': ['bearing wear', 'valve fault', 'compressor stall', 'unbalance', 'eccentric impeller'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1719, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?\\nOptions:\\nA noise\\nB frequency response analysis (fra)\\nC vibration\\nD ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of winding looseness in power transformer?', 'options_text': ['noise', 'frequency response analysis (fra)', 'vibration', 'ultrasound'], 'true_answer': [False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:One thread 50 / 334 samples completed.\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2387, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of electric generator, which failure event is not relevant when the sensor temparature shows an abnormal reading?\\nOptions:\\nA stator windings fault\\nB bearing damage\\nC brush(es) fault\\nD eccentric rotor\\nE rotor windings fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of electric generator, which failure event is not relevant when the sensor temparature shows an abnormal reading?', 'options_text': ['stator windings fault', 'bearing damage', 'brush(es) fault', 'eccentric rotor', 'rotor windings fault'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 50 / 334 samples completed.\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 383, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices can indicate the presence of insulation deterioration in asset power transformer?\\nOptions:\\nA bushing capacitance\\nB vibration\\nC amps/ volts/ load\\nD noise\\nE visual\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices can indicate the presence of insulation deterioration in asset power transformer?', 'options_text': ['bushing capacitance', 'vibration', 'amps/ volts/ load', 'noise', 'visual'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2053, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor fuel pressure/ fuel flow in industrial gas turbine displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA compressor fouled\\nB burner blocked\\nC fuel filter blockage\\nD misalignment\\nE compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor fuel pressure/ fuel flow in industrial gas turbine displays an abnormal reading, which failure event is not applicable?', 'options_text': ['compressor fouled', 'burner blocked', 'fuel filter blockage', 'misalignment', 'compressor damaged'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of compressor, which failure mode is most relevant when oil debris shows abnormal readings?\n",
      "Options:\n",
      "A unbalance\n",
      "B misalignment\n",
      "C eccentric impeller\n",
      "D mounting fault\n",
      "E cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:One thread 50 / 329 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a power transformer has winding looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A ultrasound\n",
      "B vibration\n",
      "C noise\n",
      "D excitation current\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:One thread 50 / 334 samples completed.\n",
      "INFO:root:One thread 50 / 334 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In electric generator, which failure event is unimportant if the sensor temparature shows an abnormal reading?\n",
      "Options:\n",
      "A rotor windings fault\n",
      "B insulation deterioration\n",
      "C stator windings fault\n",
      "D bearing damage\n",
      "E brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with insulation deterioration in power transformer, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A oil condition\n",
      "B leak reactance flux\n",
      "C vibration\n",
      "D bushing capacitance\n",
      "E visual\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of industrial gas turbine, which failure event is not relevant when the sensor speed shows an abnormal reading?\n",
      "Options:\n",
      "A fuel filter blockage\n",
      "B air inlet blockage\n",
      "C combustion chamber holed\n",
      "D power turbine damaged\n",
      "E bearing wear\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 718, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of compressor, which failure mode is most relevant when oil debris shows abnormal readings?\\nOptions:\\nA unbalance\\nB misalignment\\nC eccentric impeller\\nD mounting fault\\nE cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of compressor, which failure mode is most relevant when oil debris shows abnormal readings?', 'options_text': ['unbalance', 'misalignment', 'eccentric impeller', 'mounting fault', 'cooling system fault'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2388, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In electric generator, which failure event is unimportant if the sensor temparature shows an abnormal reading?\\nOptions:\\nA rotor windings fault\\nB insulation deterioration\\nC stator windings fault\\nD bearing damage\\nE brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In electric generator, which failure event is unimportant if the sensor temparature shows an abnormal reading?', 'options_text': ['rotor windings fault', 'insulation deterioration', 'stator windings fault', 'bearing damage', 'brush(es) fault'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If oil leakage in compressor shows abnormal readings, which failure mode is most significant?\n",
      "Options:\n",
      "A bearing damage\n",
      "B unbalance\n",
      "C misalignment\n",
      "D mounting fault\n",
      "E valve fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2054, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of industrial gas turbine, which failure event is not relevant when the sensor speed shows an abnormal reading?\\nOptions:\\nA fuel filter blockage\\nB air inlet blockage\\nC combustion chamber holed\\nD power turbine damaged\\nE bearing wear\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of industrial gas turbine, which failure event is not relevant when the sensor speed shows an abnormal reading?', 'options_text': ['fuel filter blockage', 'air inlet blockage', 'combustion chamber holed', 'power turbine damaged', 'bearing wear'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 384, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with insulation deterioration in power transformer, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA oil condition\\nB leak reactance flux\\nC vibration\\nD bushing capacitance\\nE visual\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with insulation deterioration in power transformer, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['oil condition', 'leak reactance flux', 'vibration', 'bushing capacitance', 'visual'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for electric generator if the sensor temparature exhibits an abnormal reading?\n",
      "Options:\n",
      "A rotor windings fault\n",
      "B bearing damage\n",
      "C stator windings fault\n",
      "D loss of output power phase\n",
      "E brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1720, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a power transformer has winding looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA ultrasound\\nB vibration\\nC noise\\nD excitation current\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a power transformer has winding looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['ultrasound', 'vibration', 'noise', 'excitation current'], 'true_answer': [False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor speed in industrial gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A compressor fouled\n",
      "B burner blocked\n",
      "C fuel filter blockage\n",
      "D combustion chamber holed\n",
      "E unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a power transformer has insulation deterioration, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A noise\n",
      "B vibration\n",
      "C leak reactance flux\n",
      "D visual\n",
      "E temperature\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a power transformer has winding looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A leak reactance flux\n",
      "B noise\n",
      "C vibration\n",
      "D ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "51\n",
      "51\n",
      "51\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2389, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for electric generator if the sensor temparature exhibits an abnormal reading?\\nOptions:\\nA rotor windings fault\\nB bearing damage\\nC stator windings fault\\nD loss of output power phase\\nE brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for electric generator if the sensor temparature exhibits an abnormal reading?', 'options_text': ['rotor windings fault', 'bearing damage', 'stator windings fault', 'loss of output power phase', 'brush(es) fault'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1721, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a power transformer has winding looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA leak reactance flux\\nB noise\\nC vibration\\nD ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a power transformer has winding looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['leak reactance flux', 'noise', 'vibration', 'ultrasound'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, what is the non-relevant failure event when the sensor temparature has an abnormal reading?\n",
      "Options:\n",
      "A unbalance\n",
      "B brush(es) fault\n",
      "C rotor windings fault\n",
      "D bearing damage\n",
      "E stator windings fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 719, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If oil leakage in compressor shows abnormal readings, which failure mode is most significant?\\nOptions:\\nA bearing damage\\nB unbalance\\nC misalignment\\nD mounting fault\\nE valve fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If oil leakage in compressor shows abnormal readings, which failure mode is most significant?', 'options_text': ['bearing damage', 'unbalance', 'misalignment', 'mounting fault', 'valve fault'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In power transformer, which sensor among the choices is least useful for detecting winding looseness?\n",
      "Options:\n",
      "A ultrasound\n",
      "B noise\n",
      "C bushing capacitance\n",
      "D vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 385, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a power transformer has insulation deterioration, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA noise\\nB vibration\\nC leak reactance flux\\nD visual\\nE temperature\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a power transformer has insulation deterioration, which sensor out of the choices should be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['noise', 'vibration', 'leak reactance flux', 'visual', 'temperature'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2055, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor speed in industrial gas turbine, which failure event is not relevant?\\nOptions:\\nA compressor fouled\\nB burner blocked\\nC fuel filter blockage\\nD combustion chamber holed\\nE unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor speed in industrial gas turbine, which failure event is not relevant?', 'options_text': ['compressor fouled', 'burner blocked', 'fuel filter blockage', 'combustion chamber holed', 'unbalance'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of reciprocating internal combustion engine, which failure mode is most relevant when engine temperature shows abnormal readings?\n",
      "Options:\n",
      "A air inlet blockage\n",
      "B bearing wear\n",
      "C misalignment\n",
      "D mounting fault\n",
      "E cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In power transformer, when insulation deterioration occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\n",
      "Options:\n",
      "A bushing capacitance\n",
      "B partial discharge\n",
      "C vibration\n",
      "D visual\n",
      "E noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In industrial gas turbine, which failure event is unimportant if the sensor speed shows an abnormal reading?\n",
      "Options:\n",
      "A burner blocked\n",
      "B misalignment\n",
      "C air inlet blockage\n",
      "D combustion chamber holed\n",
      "E power turbine damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "52\n",
      "52\n",
      "52\n",
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2390, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, what is the non-relevant failure event when the sensor temparature has an abnormal reading?\\nOptions:\\nA unbalance\\nB brush(es) fault\\nC rotor windings fault\\nD bearing damage\\nE stator windings fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, what is the non-relevant failure event when the sensor temparature has an abnormal reading?', 'options_text': ['unbalance', 'brush(es) fault', 'rotor windings fault', 'bearing damage', 'stator windings fault'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 386, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In power transformer, when insulation deterioration occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\\nOptions:\\nA bushing capacitance\\nB partial discharge\\nC vibration\\nD visual\\nE noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In power transformer, when insulation deterioration occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?', 'options_text': ['bushing capacitance', 'partial discharge', 'vibration', 'visual', 'noise'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1722, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In power transformer, which sensor among the choices is least useful for detecting winding looseness?\\nOptions:\\nA ultrasound\\nB noise\\nC bushing capacitance\\nD vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In power transformer, which sensor among the choices is least useful for detecting winding looseness?', 'options_text': ['ultrasound', 'noise', 'bushing capacitance', 'vibration'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2056, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In industrial gas turbine, which failure event is unimportant if the sensor speed shows an abnormal reading?\\nOptions:\\nA burner blocked\\nB misalignment\\nC air inlet blockage\\nD combustion chamber holed\\nE power turbine damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In industrial gas turbine, which failure event is unimportant if the sensor speed shows an abnormal reading?', 'options_text': ['burner blocked', 'misalignment', 'air inlet blockage', 'combustion chamber holed', 'power turbine damaged'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 720, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of reciprocating internal combustion engine, which failure mode is most relevant when engine temperature shows abnormal readings?\\nOptions:\\nA air inlet blockage\\nB bearing wear\\nC misalignment\\nD mounting fault\\nE cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of reciprocating internal combustion engine, which failure mode is most relevant when engine temperature shows abnormal readings?', 'options_text': ['air inlet blockage', 'bearing wear', 'misalignment', 'mounting fault', 'cooling system fault'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor temparature?\n",
      "Options:\n",
      "A brush(es) fault\n",
      "B rotor windings fault\n",
      "C stator windings fault\n",
      "D bearing damage\n",
      "E misalignment\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor among the choices best correlates with the presence of insulation deterioration in asset power transformer?\n",
      "Options:\n",
      "A visual\n",
      "B noise\n",
      "C vibration\n",
      "D bushing capacitance\n",
      "E dissolved gas analysis\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting core looseness in power transformer?\n",
      "Options:\n",
      "A ultrasound\n",
      "B noise\n",
      "C amps/ volts/ load\n",
      "D vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor exhaust temperature?\n",
      "Options:\n",
      "A power turbine damaged\n",
      "B air inlet blockage\n",
      "C burner blocked\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the most relevant failure mode for reciprocating internal combustion engine if engine temperature exhibits abnormal readings?\n",
      "Options:\n",
      "A bearing wear\n",
      "B unbalance\n",
      "C piston ring fault\n",
      "D fuel injector fault\n",
      "E cooling system fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "53\n",
      "53\n",
      "53\n",
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2057, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor exhaust temperature?\\nOptions:\\nA power turbine damaged\\nB air inlet blockage\\nC burner blocked\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor exhaust temperature?', 'options_text': ['power turbine damaged', 'air inlet blockage', 'burner blocked'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1723, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor from the choices does not contribute significantly to detecting core looseness in power transformer?\\nOptions:\\nA ultrasound\\nB noise\\nC amps/ volts/ load\\nD vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor from the choices does not contribute significantly to detecting core looseness in power transformer?', 'options_text': ['ultrasound', 'noise', 'amps/ volts/ load', 'vibration'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor exhaust temperature in industrial gas turbine shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A burner blocked\n",
      "B power turbine damaged\n",
      "C compressor fouled\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 387, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor among the choices best correlates with the presence of insulation deterioration in asset power transformer?\\nOptions:\\nA visual\\nB noise\\nC vibration\\nD bushing capacitance\\nE dissolved gas analysis\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor among the choices best correlates with the presence of insulation deterioration in asset power transformer?', 'options_text': ['visual', 'noise', 'vibration', 'bushing capacitance', 'dissolved gas analysis'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2391, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor temparature?\\nOptions:\\nA brush(es) fault\\nB rotor windings fault\\nC stator windings fault\\nD bearing damage\\nE misalignment\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for electric generator when an abnormal reading is detected by the sensor temparature?', 'options_text': ['brush(es) fault', 'rotor windings fault', 'stator windings fault', 'bearing damage', 'misalignment'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting core looseness in power transformer?\n",
      "Options:\n",
      "A visual\n",
      "B ultrasound\n",
      "C noise\n",
      "D vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 721, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the most relevant failure mode for reciprocating internal combustion engine if engine temperature exhibits abnormal readings?\\nOptions:\\nA bearing wear\\nB unbalance\\nC piston ring fault\\nD fuel injector fault\\nE cooling system fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the most relevant failure mode for reciprocating internal combustion engine if engine temperature exhibits abnormal readings?', 'options_text': ['bearing wear', 'unbalance', 'piston ring fault', 'fuel injector fault', 'cooling system fault'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices provides the strongest indication of insulation deterioration in power transformer?\n",
      "Options:\n",
      "A vibration\n",
      "B visual\n",
      "C ultrasound\n",
      "D bushing capacitance\n",
      "E noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor coast down in electric generator displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A rotor windings fault\n",
      "B bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For reciprocating internal combustion engine, which failure mode is pertinent if engine temperature registers abnormal readings?\n",
      "Options:\n",
      "A ignition fault\n",
      "B bearing wear\n",
      "C seal leakage\n",
      "D unbalance\n",
      "E piston ring fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "54\n",
      "54\n",
      "54\n",
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 722, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For reciprocating internal combustion engine, which failure mode is pertinent if engine temperature registers abnormal readings?\\nOptions:\\nA ignition fault\\nB bearing wear\\nC seal leakage\\nD unbalance\\nE piston ring fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For reciprocating internal combustion engine, which failure mode is pertinent if engine temperature registers abnormal readings?', 'options_text': ['ignition fault', 'bearing wear', 'seal leakage', 'unbalance', 'piston ring fault'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2392, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor coast down in electric generator displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA rotor windings fault\\nB bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor coast down in electric generator displays an abnormal reading, which failure event is not applicable?', 'options_text': ['rotor windings fault', 'bearing damage'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When cylinder pressure detects abnormal readings in reciprocating internal combustion engine, which failure mode is the most relevant?\n",
      "Options:\n",
      "A gear defects\n",
      "B bearing wear\n",
      "C air inlet blockage\n",
      "D mounting fault\n",
      "E flywheel damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1724, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor from the choices does not contribute significantly to detecting core looseness in power transformer?\\nOptions:\\nA visual\\nB ultrasound\\nC noise\\nD vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor from the choices does not contribute significantly to detecting core looseness in power transformer?', 'options_text': ['visual', 'ultrasound', 'noise', 'vibration'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor coast down in electric generator, which failure event is not relevant?\n",
      "Options:\n",
      "A bearing damage\n",
      "B stator windings fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2058, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor exhaust temperature in industrial gas turbine shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA burner blocked\\nB power turbine damaged\\nC compressor fouled\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor exhaust temperature in industrial gas turbine shows an abnormal reading, which failure event is insignificant?', 'options_text': ['burner blocked', 'power turbine damaged', 'compressor fouled'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 388, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices provides the strongest indication of insulation deterioration in power transformer?\\nOptions:\\nA vibration\\nB visual\\nC ultrasound\\nD bushing capacitance\\nE noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices provides the strongest indication of insulation deterioration in power transformer?', 'options_text': ['vibration', 'visual', 'ultrasound', 'bushing capacitance', 'noise'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices is not effective in indicating the presence of core looseness in power transformer?\n",
      "Options:\n",
      "A oil condition\n",
      "B noise\n",
      "C ultrasound\n",
      "D vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor exhaust temperature in industrial gas turbine shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A power turbine damaged\n",
      "B burner blocked\n",
      "C compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In power transformer, when insulation deterioration occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\n",
      "Options:\n",
      "A bushing capacitance\n",
      "B noise\n",
      "C visual\n",
      "D power factor/tanδ\n",
      "E vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 389, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In power transformer, when insulation deterioration occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?\\nOptions:\\nA bushing capacitance\\nB noise\\nC visual\\nD power factor/tanδ\\nE vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In power transformer, when insulation deterioration occurs, which sensor from the choices is most critical in detecting the occurrence of the failure event?', 'options_text': ['bushing capacitance', 'noise', 'visual', 'power factor/tanδ', 'vibration'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with insulation deterioration in power transformer, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A leak reactance flux\n",
      "B visual\n",
      "C resistance\n",
      "D vibration\n",
      "E noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1725, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices is not effective in indicating the presence of core looseness in power transformer?\\nOptions:\\nA oil condition\\nB noise\\nC ultrasound\\nD vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices is not effective in indicating the presence of core looseness in power transformer?', 'options_text': ['oil condition', 'noise', 'ultrasound', 'vibration'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2393, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor coast down in electric generator, which failure event is not relevant?\\nOptions:\\nA bearing damage\\nB stator windings fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor coast down in electric generator, which failure event is not relevant?', 'options_text': ['bearing damage', 'stator windings fault'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 723, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When cylinder pressure detects abnormal readings in reciprocating internal combustion engine, which failure mode is the most relevant?\\nOptions:\\nA gear defects\\nB bearing wear\\nC air inlet blockage\\nD mounting fault\\nE flywheel damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When cylinder pressure detects abnormal readings in reciprocating internal combustion engine, which failure mode is the most relevant?', 'options_text': ['gear defects', 'bearing wear', 'air inlet blockage', 'mounting fault', 'flywheel damage'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2059, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If the sensor exhaust temperature in industrial gas turbine shows an abnormal reading, which failure event is insignificant?\\nOptions:\\nA power turbine damaged\\nB burner blocked\\nC compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If the sensor exhaust temperature in industrial gas turbine shows an abnormal reading, which failure event is insignificant?', 'options_text': ['power turbine damaged', 'burner blocked', 'compressor damaged'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices does not indicate the presence of core looseness in asset power transformer?\n",
      "Options:\n",
      "A temperature\n",
      "B ultrasound\n",
      "C noise\n",
      "D vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, which failure event is not pertinent if the sensor coast down registers an abnormal reading?\n",
      "Options:\n",
      "A bearing damage\n",
      "B eccentric rotor\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode should be considered for reciprocating internal combustion engine when abnormal readings is detected by cylinder pressure?\n",
      "Options:\n",
      "A unbalance\n",
      "B fuel filter blockage\n",
      "C fuel injector fault\n",
      "D flywheel damage\n",
      "E gear defects\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor exhaust temperature?\n",
      "Options:\n",
      "A burner blocked\n",
      "B power turbine damaged\n",
      "C fuel filter blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "56\n",
      "56\n",
      "56\n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2394, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, which failure event is not pertinent if the sensor coast down registers an abnormal reading?\\nOptions:\\nA bearing damage\\nB eccentric rotor\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, which failure event is not pertinent if the sensor coast down registers an abnormal reading?', 'options_text': ['bearing damage', 'eccentric rotor'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor coast down in electric generator displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A bearing damage\n",
      "B brush(es) fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2060, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor exhaust temperature?\\nOptions:\\nA burner blocked\\nB power turbine damaged\\nC fuel filter blockage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor exhaust temperature?', 'options_text': ['burner blocked', 'power turbine damaged', 'fuel filter blockage'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 724, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode should be considered for reciprocating internal combustion engine when abnormal readings is detected by cylinder pressure?\\nOptions:\\nA unbalance\\nB fuel filter blockage\\nC fuel injector fault\\nD flywheel damage\\nE gear defects\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode should be considered for reciprocating internal combustion engine when abnormal readings is detected by cylinder pressure?', 'options_text': ['unbalance', 'fuel filter blockage', 'fuel injector fault', 'flywheel damage', 'gear defects'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1726, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices does not indicate the presence of core looseness in asset power transformer?\\nOptions:\\nA temperature\\nB ultrasound\\nC noise\\nD vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices does not indicate the presence of core looseness in asset power transformer?', 'options_text': ['temperature', 'ultrasound', 'noise', 'vibration'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 390, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with insulation deterioration in power transformer, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA leak reactance flux\\nB visual\\nC resistance\\nD vibration\\nE noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with insulation deterioration in power transformer, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['leak reactance flux', 'visual', 'resistance', 'vibration', 'noise'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor exhaust temperature in industrial gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A power turbine damaged\n",
      "B burner blocked\n",
      "C combustion chamber holed\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If cylinder pressure in reciprocating internal combustion engine shows abnormal readings, which failure mode is most significant?\n",
      "Options:\n",
      "A misalignment\n",
      "B ignition fault\n",
      "C cooling system fault\n",
      "D unbalance\n",
      "E bearing wear\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In power transformer, which sensor among the choices is least useful for detecting core looseness?\n",
      "Options:\n",
      "A noise\n",
      "B vibration\n",
      "C ultrasound\n",
      "D partial discharge\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices can indicate the presence of insulation deterioration in asset power transformer?\n",
      "Options:\n",
      "A vibration\n",
      "B visual\n",
      "C bushing capacitance\n",
      "D dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "E leak reactance flux\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 725, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: If cylinder pressure in reciprocating internal combustion engine shows abnormal readings, which failure mode is most significant?\\nOptions:\\nA misalignment\\nB ignition fault\\nC cooling system fault\\nD unbalance\\nE bearing wear\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'If cylinder pressure in reciprocating internal combustion engine shows abnormal readings, which failure mode is most significant?', 'options_text': ['misalignment', 'ignition fault', 'cooling system fault', 'unbalance', 'bearing wear'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2395, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor coast down in electric generator displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA bearing damage\\nB brush(es) fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor coast down in electric generator displays an abnormal reading, which failure event is not applicable?', 'options_text': ['bearing damage', 'brush(es) fault'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode should be considered for reciprocating internal combustion engine when abnormal readings is detected by cylinder pressure?\n",
      "Options:\n",
      "A piston ring fault\n",
      "B secondary balance gear fault\n",
      "C gear defects\n",
      "D cooling system fault\n",
      "E mounting fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 391, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices can indicate the presence of insulation deterioration in asset power transformer?\\nOptions:\\nA vibration\\nB visual\\nC bushing capacitance\\nD dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nE leak reactance flux\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices can indicate the presence of insulation deterioration in asset power transformer?', 'options_text': ['vibration', 'visual', 'bushing capacitance', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'leak reactance flux'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor coast down in electric generator, which failure event is not relevant?\n",
      "Options:\n",
      "A insulation deterioration\n",
      "B bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2061, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor exhaust temperature in industrial gas turbine, which failure event is not relevant?\\nOptions:\\nA power turbine damaged\\nB burner blocked\\nC combustion chamber holed\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor exhaust temperature in industrial gas turbine, which failure event is not relevant?', 'options_text': ['power turbine damaged', 'burner blocked', 'combustion chamber holed'], 'true_answer': [False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1727, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In power transformer, which sensor among the choices is least useful for detecting core looseness?\\nOptions:\\nA noise\\nB vibration\\nC ultrasound\\nD partial discharge\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In power transformer, which sensor among the choices is least useful for detecting core looseness?', 'options_text': ['noise', 'vibration', 'ultrasound', 'partial discharge'], 'true_answer': [False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor among the choices best correlates with the presence of insulation deterioration in asset power transformer?\n",
      "Options:\n",
      "A vibration\n",
      "B leak reactance flux\n",
      "C frequency response analysis (fra)\n",
      "D visual\n",
      "E noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor exhaust temperature in industrial gas turbine displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A bearing wear\n",
      "B power turbine damaged\n",
      "C burner blocked\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In power transformer, which sensor among the choices is least useful for detecting core looseness?\n",
      "Options:\n",
      "A dissolved gas analysis\n",
      "B vibration\n",
      "C ultrasound\n",
      "D noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "58\n",
      "58\n",
      "58\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1728, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In power transformer, which sensor among the choices is least useful for detecting core looseness?\\nOptions:\\nA dissolved gas analysis\\nB vibration\\nC ultrasound\\nD noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In power transformer, which sensor among the choices is least useful for detecting core looseness?', 'options_text': ['dissolved gas analysis', 'vibration', 'ultrasound', 'noise'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor from the choices does not contribute significantly to detecting core looseness in power transformer?\n",
      "Options:\n",
      "A vibration\n",
      "B noise\n",
      "C ultrasound\n",
      "D power factor/tanδ\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2396, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor coast down in electric generator, which failure event is not relevant?\\nOptions:\\nA insulation deterioration\\nB bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor coast down in electric generator, which failure event is not relevant?', 'options_text': ['insulation deterioration', 'bearing damage'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 726, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode should be considered for reciprocating internal combustion engine when abnormal readings is detected by cylinder pressure?\\nOptions:\\nA piston ring fault\\nB secondary balance gear fault\\nC gear defects\\nD cooling system fault\\nE mounting fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode should be considered for reciprocating internal combustion engine when abnormal readings is detected by cylinder pressure?', 'options_text': ['piston ring fault', 'secondary balance gear fault', 'gear defects', 'cooling system fault', 'mounting fault'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2062, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor exhaust temperature in industrial gas turbine displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA bearing wear\\nB power turbine damaged\\nC burner blocked\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor exhaust temperature in industrial gas turbine displays an abnormal reading, which failure event is not applicable?', 'options_text': ['bearing wear', 'power turbine damaged', 'burner blocked'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 392, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor among the choices best correlates with the presence of insulation deterioration in asset power transformer?\\nOptions:\\nA vibration\\nB leak reactance flux\\nC frequency response analysis (fra)\\nD visual\\nE noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor among the choices best correlates with the presence of insulation deterioration in asset power transformer?', 'options_text': ['vibration', 'leak reactance flux', 'frequency response analysis (fra)', 'visual', 'noise'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor coast down in electric generator, which failure event is not relevant?\n",
      "Options:\n",
      "A loss of output power phase\n",
      "B bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For reciprocating internal combustion engine, what is the key failure mode when air flow has abnormal readings?\n",
      "Options:\n",
      "A fuel filter blockage\n",
      "B seal leakage\n",
      "C piston ring fault\n",
      "D secondary balance gear fault\n",
      "E air inlet blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor exhaust temperature in industrial gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A unbalance\n",
      "B burner blocked\n",
      "C power turbine damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices provides the strongest indication of insulation deterioration in power transformer?\n",
      "Options:\n",
      "A bushing capacitance\n",
      "B leak reactance flux\n",
      "C excitation current\n",
      "D visual\n",
      "E vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "59\n",
      "59\n",
      "59\n",
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 727, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For reciprocating internal combustion engine, what is the key failure mode when air flow has abnormal readings?\\nOptions:\\nA fuel filter blockage\\nB seal leakage\\nC piston ring fault\\nD secondary balance gear fault\\nE air inlet blockage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For reciprocating internal combustion engine, what is the key failure mode when air flow has abnormal readings?', 'options_text': ['fuel filter blockage', 'seal leakage', 'piston ring fault', 'secondary balance gear fault', 'air inlet blockage'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 393, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices provides the strongest indication of insulation deterioration in power transformer?\\nOptions:\\nA bushing capacitance\\nB leak reactance flux\\nC excitation current\\nD visual\\nE vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices provides the strongest indication of insulation deterioration in power transformer?', 'options_text': ['bushing capacitance', 'leak reactance flux', 'excitation current', 'visual', 'vibration'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:One thread 60 / 334 samples completed.\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1729, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor from the choices does not contribute significantly to detecting core looseness in power transformer?\\nOptions:\\nA vibration\\nB noise\\nC ultrasound\\nD power factor/tanδ\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor from the choices does not contribute significantly to detecting core looseness in power transformer?', 'options_text': ['vibration', 'noise', 'ultrasound', 'power factor/tanδ'], 'true_answer': [False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2397, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor coast down in electric generator, which failure event is not relevant?\\nOptions:\\nA loss of output power phase\\nB bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor coast down in electric generator, which failure event is not relevant?', 'options_text': ['loss of output power phase', 'bearing damage'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:One thread 60 / 334 samples completed.\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2063, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor exhaust temperature in industrial gas turbine, which failure event is not relevant?\\nOptions:\\nA unbalance\\nB burner blocked\\nC power turbine damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor exhaust temperature in industrial gas turbine, which failure event is not relevant?', 'options_text': ['unbalance', 'burner blocked', 'power turbine damaged'], 'true_answer': [True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure mode should be considered for reciprocating internal combustion engine when abnormal readings is detected by air flow?\n",
      "Options:\n",
      "A unbalance\n",
      "B secondary balance gear fault\n",
      "C misalignment\n",
      "D ignition fault\n",
      "E fuel injector fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:One thread 60 / 334 samples completed.\n",
      "INFO:root:One thread 60 / 329 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with moisture ingress/ content in power transformer, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A temperature\n",
      "B visual\n",
      "C oil condition\n",
      "D noise\n",
      "E frequency response analysis (fra)\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:One thread 60 / 334 samples completed.\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if a failure event core looseness occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A ultrasound\n",
      "B noise\n",
      "C resistance\n",
      "D vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for electric generator if the sensor coast down exhibits an abnormal reading?\n",
      "Options:\n",
      "A bearing damage\n",
      "B unbalance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor exhaust temperature in industrial gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A burner blocked\n",
      "B misalignment\n",
      "C power turbine damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1730, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if a failure event core looseness occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?\\nOptions:\\nA ultrasound\\nB noise\\nC resistance\\nD vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if a failure event core looseness occurs, which sensor out of the choices is not relevant regarding the occurrence of the failure event?', 'options_text': ['ultrasound', 'noise', 'resistance', 'vibration'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a power transformer has core looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "B vibration\n",
      "C noise\n",
      "D ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2398, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for electric generator if the sensor coast down exhibits an abnormal reading?\\nOptions:\\nA bearing damage\\nB unbalance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for electric generator if the sensor coast down exhibits an abnormal reading?', 'options_text': ['bearing damage', 'unbalance'], 'true_answer': [False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 728, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure mode should be considered for reciprocating internal combustion engine when abnormal readings is detected by air flow?\\nOptions:\\nA unbalance\\nB secondary balance gear fault\\nC misalignment\\nD ignition fault\\nE fuel injector fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure mode should be considered for reciprocating internal combustion engine when abnormal readings is detected by air flow?', 'options_text': ['unbalance', 'secondary balance gear fault', 'misalignment', 'ignition fault', 'fuel injector fault'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 394, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with moisture ingress/ content in power transformer, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA temperature\\nB visual\\nC oil condition\\nD noise\\nE frequency response analysis (fra)\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with moisture ingress/ content in power transformer, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['temperature', 'visual', 'oil condition', 'noise', 'frequency response analysis (fra)'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, what is the non-relevant failure event when the sensor coast down has an abnormal reading?\n",
      "Options:\n",
      "A misalignment\n",
      "B bearing damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2064, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor exhaust temperature in industrial gas turbine, which failure event is not relevant?\\nOptions:\\nA burner blocked\\nB misalignment\\nC power turbine damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor exhaust temperature in industrial gas turbine, which failure event is not relevant?', 'options_text': ['burner blocked', 'misalignment', 'power turbine damaged'], 'true_answer': [False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For reciprocating internal combustion engine, what is the key failure mode when fuel pressure has abnormal readings?\n",
      "Options:\n",
      "A fuel filter blockage\n",
      "B mounting fault\n",
      "C bearing wear\n",
      "D seal leakage\n",
      "E secondary balance gear fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When dealing with moisture ingress/ content in power transformer, which sensor among the choices has the highest relevance in detecting this issue?\n",
      "Options:\n",
      "A excitation current\n",
      "B visual\n",
      "C bushing capacitance\n",
      "D dissolved gas analysis\n",
      "E amps/ volts/ load\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor vibration?\n",
      "Options:\n",
      "A bearing wear\n",
      "B air inlet blockage\n",
      "C unbalance\n",
      "D power turbine damaged\n",
      "E misalignment\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2065, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor vibration?\\nOptions:\\nA bearing wear\\nB air inlet blockage\\nC unbalance\\nD power turbine damaged\\nE misalignment\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor vibration?', 'options_text': ['bearing wear', 'air inlet blockage', 'unbalance', 'power turbine damaged', 'misalignment'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2399, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, what is the non-relevant failure event when the sensor coast down has an abnormal reading?\\nOptions:\\nA misalignment\\nB bearing damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, what is the non-relevant failure event when the sensor coast down has an abnormal reading?', 'options_text': ['misalignment', 'bearing damage'], 'true_answer': [True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor vibration?\n",
      "Options:\n",
      "A bearing wear\n",
      "B compressor fouled\n",
      "C unbalance\n",
      "D power turbine damaged\n",
      "E compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 729, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For reciprocating internal combustion engine, what is the key failure mode when fuel pressure has abnormal readings?\\nOptions:\\nA fuel filter blockage\\nB mounting fault\\nC bearing wear\\nD seal leakage\\nE secondary balance gear fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For reciprocating internal combustion engine, what is the key failure mode when fuel pressure has abnormal readings?', 'options_text': ['fuel filter blockage', 'mounting fault', 'bearing wear', 'seal leakage', 'secondary balance gear fault'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 395, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When dealing with moisture ingress/ content in power transformer, which sensor among the choices has the highest relevance in detecting this issue?\\nOptions:\\nA excitation current\\nB visual\\nC bushing capacitance\\nD dissolved gas analysis\\nE amps/ volts/ load\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When dealing with moisture ingress/ content in power transformer, which sensor among the choices has the highest relevance in detecting this issue?', 'options_text': ['excitation current', 'visual', 'bushing capacitance', 'dissolved gas analysis', 'amps/ volts/ load'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For electric generator, what is the non-relevant failure event when the sensor axial flux has an abnormal reading?\n",
      "Options:\n",
      "A stator windings fault\n",
      "B brush(es) fault\n",
      "C rotor windings fault\n",
      "D eccentric rotor\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1731, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a power transformer has core looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nB vibration\\nC noise\\nD ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a power transformer has core looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'vibration', 'noise', 'ultrasound'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When fuel flow in reciprocating internal combustion engine displays abnormal readings, which failure mode is the most applicable?\n",
      "Options:\n",
      "A air inlet blockage\n",
      "B fuel injector fault\n",
      "C misalignment\n",
      "D secondary balance gear fault\n",
      "E flywheel damage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices provides the strongest indication of moisture ingress/ content in power transformer?\n",
      "Options:\n",
      "A bushing capacitance\n",
      "B vibration\n",
      "C power factor/tanδ\n",
      "D noise\n",
      "E amps/ volts/ load\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices does not indicate the presence of core looseness in asset power transformer?\n",
      "Options:\n",
      "A noise\n",
      "B vibration\n",
      "C frequency response analysis (fra)\n",
      "D ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 396, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices provides the strongest indication of moisture ingress/ content in power transformer?\\nOptions:\\nA bushing capacitance\\nB vibration\\nC power factor/tanδ\\nD noise\\nE amps/ volts/ load\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices provides the strongest indication of moisture ingress/ content in power transformer?', 'options_text': ['bushing capacitance', 'vibration', 'power factor/tanδ', 'noise', 'amps/ volts/ load'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2400, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For electric generator, what is the non-relevant failure event when the sensor axial flux has an abnormal reading?\\nOptions:\\nA stator windings fault\\nB brush(es) fault\\nC rotor windings fault\\nD eccentric rotor\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For electric generator, what is the non-relevant failure event when the sensor axial flux has an abnormal reading?', 'options_text': ['stator windings fault', 'brush(es) fault', 'rotor windings fault', 'eccentric rotor'], 'true_answer': [False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 730, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When fuel flow in reciprocating internal combustion engine displays abnormal readings, which failure mode is the most applicable?\\nOptions:\\nA air inlet blockage\\nB fuel injector fault\\nC misalignment\\nD secondary balance gear fault\\nE flywheel damage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When fuel flow in reciprocating internal combustion engine displays abnormal readings, which failure mode is the most applicable?', 'options_text': ['air inlet blockage', 'fuel injector fault', 'misalignment', 'secondary balance gear fault', 'flywheel damage'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1732, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices does not indicate the presence of core looseness in asset power transformer?\\nOptions:\\nA noise\\nB vibration\\nC frequency response analysis (fra)\\nD ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices does not indicate the presence of core looseness in asset power transformer?', 'options_text': ['noise', 'vibration', 'frequency response analysis (fra)', 'ultrasound'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor out of the choices can indicate the presence of moisture ingress/ content in asset power transformer?\n",
      "Options:\n",
      "A bushing capacitance\n",
      "B leak reactance flux\n",
      "C amps/ volts/ load\n",
      "D excitation current\n",
      "E resistance\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2066, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor vibration?\\nOptions:\\nA bearing wear\\nB compressor fouled\\nC unbalance\\nD power turbine damaged\\nE compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event is irrelevant for industrial gas turbine if there is an abnormal reading from the sensor vibration?', 'options_text': ['bearing wear', 'compressor fouled', 'unbalance', 'power turbine damaged', 'compressor damaged'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor axial flux in electric generator, which failure event is not relevant?\n",
      "Options:\n",
      "A eccentric rotor\n",
      "B rotor windings fault\n",
      "C bearing damage\n",
      "D stator windings fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of reciprocating internal combustion engine, which failure mode is most relevant when fuel flow shows abnormal readings?\n",
      "Options:\n",
      "A seal leakage\n",
      "B air inlet blockage\n",
      "C secondary balance gear fault\n",
      "D ignition fault\n",
      "E bearing wear\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When a power transformer has core looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\n",
      "Options:\n",
      "A ultrasound\n",
      "B excitation current\n",
      "C vibration\n",
      "D noise\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor vibration?\n",
      "Options:\n",
      "A bearing wear\n",
      "B compressor damaged\n",
      "C unbalance\n",
      "D power turbine damaged\n",
      "E fuel filter blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 397, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor out of the choices can indicate the presence of moisture ingress/ content in asset power transformer?\\nOptions:\\nA bushing capacitance\\nB leak reactance flux\\nC amps/ volts/ load\\nD excitation current\\nE resistance\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor out of the choices can indicate the presence of moisture ingress/ content in asset power transformer?', 'options_text': ['bushing capacitance', 'leak reactance flux', 'amps/ volts/ load', 'excitation current', 'resistance'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1733, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When a power transformer has core looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?\\nOptions:\\nA ultrasound\\nB excitation current\\nC vibration\\nD noise\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When a power transformer has core looseness, which sensor out of the choices should not be the sensor to be monitored for this failure if I want to build an anomaly detection model?', 'options_text': ['ultrasound', 'excitation current', 'vibration', 'noise'], 'true_answer': [False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: Which sensor among the choices best correlates with the presence of moisture ingress/ content in asset power transformer?\n",
      "Options:\n",
      "A frequency response analysis (fra)\n",
      "B ultrasound\n",
      "C dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "D partial discharge\n",
      "E excitation current\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 731, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of reciprocating internal combustion engine, which failure mode is most relevant when fuel flow shows abnormal readings?\\nOptions:\\nA seal leakage\\nB air inlet blockage\\nC secondary balance gear fault\\nD ignition fault\\nE bearing wear\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of reciprocating internal combustion engine, which failure mode is most relevant when fuel flow shows abnormal readings?', 'options_text': ['seal leakage', 'air inlet blockage', 'secondary balance gear fault', 'ignition fault', 'bearing wear'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if core looseness occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\n",
      "Options:\n",
      "A noise\n",
      "B leak reactance flux\n",
      "C ultrasound\n",
      "D vibration\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2067, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor vibration?\\nOptions:\\nA bearing wear\\nB compressor damaged\\nC unbalance\\nD power turbine damaged\\nE fuel filter blockage\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which failure event should be excluded for industrial gas turbine when an abnormal reading is detected by the sensor vibration?', 'options_text': ['bearing wear', 'compressor damaged', 'unbalance', 'power turbine damaged', 'fuel filter blockage'], 'true_answer': [False, False, False, False, True], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2401, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When an abnormal reading is detected by the sensor axial flux in electric generator, which failure event is not relevant?\\nOptions:\\nA eccentric rotor\\nB rotor windings fault\\nC bearing damage\\nD stator windings fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When an abnormal reading is detected by the sensor axial flux in electric generator, which failure event is not relevant?', 'options_text': ['eccentric rotor', 'rotor windings fault', 'bearing damage', 'stator windings fault'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of reciprocating internal combustion engine, which failure mode is most relevant when fuel flow shows abnormal readings?\n",
      "Options:\n",
      "A misalignment\n",
      "B unbalance\n",
      "C seal leakage\n",
      "D fuel filter blockage\n",
      "E gear defects\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In industrial gas turbine, which failure event is unimportant if the sensor vibration shows an abnormal reading?\n",
      "Options:\n",
      "A bearing wear\n",
      "B power turbine damaged\n",
      "C misalignment\n",
      "D combustion chamber holed\n",
      "E compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In the context of electric generator, which failure event is not relevant when the sensor axial flux shows an abnormal reading?\n",
      "Options:\n",
      "A eccentric rotor\n",
      "B insulation deterioration\n",
      "C stator windings fault\n",
      "D rotor windings fault\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1734, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if core looseness occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\\nOptions:\\nA noise\\nB leak reactance flux\\nC ultrasound\\nD vibration\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if core looseness occurs, which sensor among the choices is least likely to be relevant in identifying this failure?', 'options_text': ['noise', 'leak reactance flux', 'ultrasound', 'vibration'], 'true_answer': [False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 732, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of reciprocating internal combustion engine, which failure mode is most relevant when fuel flow shows abnormal readings?\\nOptions:\\nA misalignment\\nB unbalance\\nC seal leakage\\nD fuel filter blockage\\nE gear defects\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of reciprocating internal combustion engine, which failure mode is most relevant when fuel flow shows abnormal readings?', 'options_text': ['misalignment', 'unbalance', 'seal leakage', 'fuel filter blockage', 'gear defects'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2068, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In industrial gas turbine, which failure event is unimportant if the sensor vibration shows an abnormal reading?\\nOptions:\\nA bearing wear\\nB power turbine damaged\\nC misalignment\\nD combustion chamber holed\\nE compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In industrial gas turbine, which failure event is unimportant if the sensor vibration shows an abnormal reading?', 'options_text': ['bearing wear', 'power turbine damaged', 'misalignment', 'combustion chamber holed', 'compressor damaged'], 'true_answer': [False, False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In power transformer, which sensor among the choices is least useful for detecting core looseness?\n",
      "Options:\n",
      "A noise\n",
      "B vibration\n",
      "C bushing capacitance\n",
      "D ultrasound\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 398, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: Which sensor among the choices best correlates with the presence of moisture ingress/ content in asset power transformer?\\nOptions:\\nA frequency response analysis (fra)\\nB ultrasound\\nC dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nD partial discharge\\nE excitation current\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'Which sensor among the choices best correlates with the presence of moisture ingress/ content in asset power transformer?', 'options_text': ['frequency response analysis (fra)', 'ultrasound', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'partial discharge', 'excitation current'], 'true_answer': [False, False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2402, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In the context of electric generator, which failure event is not relevant when the sensor axial flux shows an abnormal reading?\\nOptions:\\nA eccentric rotor\\nB insulation deterioration\\nC stator windings fault\\nD rotor windings fault\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In the context of electric generator, which failure event is not relevant when the sensor axial flux shows an abnormal reading?', 'options_text': ['eccentric rotor', 'insulation deterioration', 'stator windings fault', 'rotor windings fault'], 'true_answer': [False, True, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When fuel flow in reciprocating internal combustion engine displays abnormal readings, which failure mode is the most applicable?\n",
      "Options:\n",
      "A cooling system fault\n",
      "B air inlet blockage\n",
      "C bearing wear\n",
      "D seal leakage\n",
      "E gear defects\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When the sensor vibration in industrial gas turbine displays an abnormal reading, which failure event is not applicable?\n",
      "Options:\n",
      "A burner blocked\n",
      "B unbalance\n",
      "C power turbine damaged\n",
      "D bearing wear\n",
      "E compressor damaged\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if on-load tap-changer condition/ fault happens, which sensor should be prioritized for monitoring this specific failure?\n",
      "Options:\n",
      "A bushing capacitance\n",
      "B amps/ volts/ load\n",
      "C dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "D leak reactance flux\n",
      "E power factor/tanδ\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: What is the irrelevant failure event for electric generator if the sensor axial flux exhibits an abnormal reading?\n",
      "Options:\n",
      "A loss of output power phase\n",
      "B stator windings fault\n",
      "C rotor windings fault\n",
      "D eccentric rotor\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "65\n",
      "65\n",
      "65\n",
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 286, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 733, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When fuel flow in reciprocating internal combustion engine displays abnormal readings, which failure mode is the most applicable?\\nOptions:\\nA cooling system fault\\nB air inlet blockage\\nC bearing wear\\nD seal leakage\\nE gear defects\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When fuel flow in reciprocating internal combustion engine displays abnormal readings, which failure mode is the most applicable?', 'options_text': ['cooling system fault', 'air inlet blockage', 'bearing wear', 'seal leakage', 'gear defects'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 399, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: For power transformer, if on-load tap-changer condition/ fault happens, which sensor should be prioritized for monitoring this specific failure?\\nOptions:\\nA bushing capacitance\\nB amps/ volts/ load\\nC dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\\nD leak reactance flux\\nE power factor/tanδ\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'For power transformer, if on-load tap-changer condition/ fault happens, which sensor should be prioritized for monitoring this specific failure?', 'options_text': ['bushing capacitance', 'amps/ volts/ load', 'dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)', 'leak reactance flux', 'power factor/tanδ'], 'true_answer': [False, True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 3\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: In reciprocating internal combustion engine, which failure mode is most important if exhaust temperature shows abnormal readings?\n",
      "Options:\n",
      "A fuel injector fault\n",
      "B bearing wear\n",
      "C air inlet blockage\n",
      "D secondary balance gear fault\n",
      "E gear defects\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2403, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: What is the irrelevant failure event for electric generator if the sensor axial flux exhibits an abnormal reading?\\nOptions:\\nA loss of output power phase\\nB stator windings fault\\nC rotor windings fault\\nD eccentric rotor\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'What is the irrelevant failure event for electric generator if the sensor axial flux exhibits an abnormal reading?', 'options_text': ['loss of output power phase', 'stator windings fault', 'rotor windings fault', 'eccentric rotor'], 'true_answer': [True, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 2069, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: When the sensor vibration in industrial gas turbine displays an abnormal reading, which failure event is not applicable?\\nOptions:\\nA burner blocked\\nB unbalance\\nC power turbine damaged\\nD bearing wear\\nE compressor damaged\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'When the sensor vibration in industrial gas turbine displays an abnormal reading, which failure event is not applicable?', 'options_text': ['burner blocked', 'unbalance', 'power turbine damaged', 'bearing wear', 'compressor damaged'], 'true_answer': [True, False, False, False, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if a failure event on-load tap-changer condition/ fault occurs, which sensor out of the choices is the most relevant sensor regarding the occurrence of the failure event?\n",
      "Options:\n",
      "A dielecric frequency response (dfr)/ polarization and de-polarization current (pdc)/ recovery voltage method (rvm)\n",
      "B oil condition\n",
      "C bushing capacitance\n",
      "D leak reactance flux\n",
      "E power factor/tanδ\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:{'subject': 'failure_mode_sensor_analysis', 'id': 1735, 'prompt': 'Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let\\'s think Step by Step reasoning strategy.\\nQuestion: In power transformer, which sensor among the choices is least useful for detecting core looseness?\\nOptions:\\nA noise\\nB vibration\\nC bushing capacitance\\nD ultrasound\\n{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\\nYour output in a single line:', 'question_text': 'In power transformer, which sensor among the choices is least useful for detecting core looseness?', 'options_text': ['noise', 'vibration', 'bushing capacitance', 'ultrasound'], 'true_answer': [False, False, True, False], 'model': 'ibm-granite/granite-3.1-8b-instruct', 'model_output': [False, False, False, False], 'model_original_output': ''}\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: If the sensor axial flux in electric generator shows an abnormal reading, which failure event is insignificant?\n",
      "Options:\n",
      "A stator windings fault\n",
      "B rotor windings fault\n",
      "C unbalance\n",
      "D eccentric rotor\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: When an abnormal reading is detected by the sensor output power in industrial gas turbine, which failure event is not relevant?\n",
      "Options:\n",
      "A power turbine damaged\n",
      "B bearing wear\n",
      "C compressor fouled\n",
      "D compressor damaged\n",
      "E air inlet blockage\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:root:prompt: Please select the correct option(s) from the following options given the question. To solve the problem, follow the Let's think Step by Step reasoning strategy.\n",
      "Question: For power transformer, if oil leak occurs, which sensor among the choices is least likely to be relevant in identifying this failure?\n",
      "Options:\n",
      "A visual\n",
      "B amps/ volts/ load\n",
      "{\"option_a\": \"<Reasoning for option a>\", \"option_b\": \"<Reasoning for option b>\", ..., \"answer\": <the list of selected option, e.g., [\"A\", \"B\", \"C\", \"D\", \"E\"]>}\n",
      "Your output in a single line:\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8003/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:original_llm_answer = \n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/KPPerturbation.py\", line 290, in get_mcq_llm_answer\n",
      "    original_response = llm.listen_and_response(prompt)\n",
      "  File \"/dccstor/dcpfactory/test/FailureSensorIQ/perteval/GeneralLLM.py\", line 269, in listen_and_response\n",
      "    response = self.client.chat.completions.create(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/u/modelfactory/.conda/envs/lab/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `ibm-granite/granite-3.1-8b-instruct` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n",
      "\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n",
      "ERROR:root:get_mcq_llm_answer: Format error, try again. n_retry = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "66\n",
      "66\n",
      "66\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "for model_name in models_todo:\n",
    "    # perteval\n",
    "    original_log_path = get_perteval_results(model_name, mode='original', cot='cot_standard', dataset=dataset)\n",
    "    print('Finished perteval on original data')\n",
    "    # wait a few seconds to kill vllm to spin up a new\n",
    "    time.sleep(10)\n",
    "    perturb_log_path = get_perteval_results(model_name, mode='perturb', cot='cot_standard', dataset=dataset)\n",
    "    print('Finished perteval on perturbed data')\n",
    "    original, perturb, consist = tas.transition_analysis(original_log_path, perturb_log_path, subjects=[\"failure_mode_sensor_analysis\"])\n",
    "    asset_scores = tas.get_record_id_for_correct_answer(original_log_path, dimention='asset_name')\n",
    "    relevancy_scores = tas.get_record_id_for_correct_answer(original_log_path, dimention='relevancy')\n",
    "    # uq on the original dataset\n",
    "    # dataset_path = 'data/fmsr'\n",
    "    # accuracy, nll_loss_avg, ece_score_avg = run_uq(model_name=model_name, dataset_path=dataset_path)\n",
    "    # uq bench\n",
    "    print('Running LLM Uncertainty Bench')\n",
    "    uq_scores = run_uq_benchmark(model_name, prompt_type='chat', dataset=dataset)\n",
    "    result_dict = {\n",
    "        \"config\": {\n",
    "            \"model_dtype\": \"torch.bfloat16\", \n",
    "            \"model_name\": model_name,\n",
    "            \"model_sha\": \"main\"\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"acc_overall\": {\n",
    "                \"acc\": original\n",
    "            },\n",
    "            \"acc_sel\": {\n",
    "                \"acc_sel\": relevancy_scores['relevant_sensor_for_failure_mode']\n",
    "            },\n",
    "            \"acc_el\": {\n",
    "                \"acc_el\": relevancy_scores['irrelevant_sensor_for_failure_mode']\n",
    "            },\n",
    "            \"acc_perturb\": {\n",
    "                \"perturb_score\": perturb\n",
    "            },\n",
    "            \"score_consistency\": {\n",
    "                \"consist_score\": consist\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    for k, v in uq_scores.items():\n",
    "        result_dict['results'][k] = {k: v}\n",
    "    for asset in asset_scores:\n",
    "        if not asset:\n",
    "            asset_lower = 'other'\n",
    "        else:\n",
    "            asset_lower = asset.lower().replace(' ', '_')\n",
    "        result_dict['results'][f'acc_{asset_lower}'] = {f'acc_{asset_lower}': asset_scores[asset]}\n",
    "    out_model_name = model_name.replace('/', '--')\n",
    "    out_fname = f'results/demo-leaderboard/gpt2-demo/results_{out_model_name}.json'\n",
    "    with open(out_fname, 'w') as f:\n",
    "        f.write(json.dumps(result_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cd46298-1e7a-4d8f-b28b-5baa1b84f966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: not enough arguments\n"
     ]
    }
   ],
   "source": [
    "# !nvidia-smi | grep 'python' | awk '{ print $5 }' | xargs -n1 kill -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41740431-b149-451a-831d-c9077adde2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
